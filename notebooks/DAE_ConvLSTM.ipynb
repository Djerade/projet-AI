{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973d71a9",
   "metadata": {},
   "source": [
    "# Partie 2 — Denoising AutoEncoder + ConvLSTM (t2f-only)\n",
    "Notebook **prêt à exécuter** :\n",
    "- t2f-only (1 canal) avec **prétraitements** (z-score + padding x8)\n",
    "- **AutoEncoder 3D** pour débruitage (Stage A)\n",
    "- **ConvLSTM 3D** sur latents (TP1→TP2) pour prédire **le masque TP3** (Stage B)\n",
    "- Sauvegarde des masques prédits dans `OUTPUT_DIR/output_masks/Patient/Timepoint/pred_mask.nii.gz`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3557f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, math, random, json\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.optim as optim\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad64f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Utils NIfTI & padding ===\n",
    "def pad_to_multiple(volume, multiple=8, mode='constant', value=0):\n",
    "    if volume.ndim == 3:\n",
    "        shape = volume.shape\n",
    "        pad_widths = []\n",
    "        for dim in shape:\n",
    "            r = dim % multiple\n",
    "            pad_widths.append((0, 0 if r == 0 else multiple - r))\n",
    "        return np.pad(volume, pad_widths, mode=mode, constant_values=value), pad_widths\n",
    "    elif volume.ndim == 4:\n",
    "        shape = volume.shape[1:]\n",
    "        pad_widths = [(0,0)]\n",
    "        for dim in shape:\n",
    "            r = dim % multiple\n",
    "            pad_widths.append((0, 0 if r == 0 else multiple - r))\n",
    "        return np.pad(volume, pad_widths, mode=mode, constant_values=value), pad_widths\n",
    "    else:\n",
    "        raise ValueError(\"Volume must be 3D or 4D\")\n",
    "\n",
    "def load_nifti(path):\n",
    "    img = nib.load(path)\n",
    "    data = img.get_fdata()\n",
    "    return data, img.affine\n",
    "\n",
    "SEQ_KEYWORDS  = [\"t2f_processed\", \"t2f\", \"flair\", \"t2_flair\", \"t2fla\"]\n",
    "MASK_KEYWORDS = [\"tumorMask\", \"mask\", \"seg\", \"label\"]\n",
    "\n",
    "def is_nifti(fname: str) -> bool:\n",
    "    low = fname.lower()\n",
    "    return low.endswith(\".nii\") or low.endswith(\".nii.gz\")\n",
    "\n",
    "def find_first_matching_file(folder: str, keywords: List[str]):\n",
    "    keys = [k.lower() for k in keywords]\n",
    "    for fname in sorted(os.listdir(folder)):\n",
    "        if not is_nifti(fname):\n",
    "            continue\n",
    "        low = fname.lower()\n",
    "        if any(k in low for k in keys):\n",
    "            return os.path.join(folder, fname)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce175ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data helpers ===\n",
    "def load_volume_and_mask(dataset_dir: str, patient: str, tp: str):\n",
    "    tp_path = os.path.join(dataset_dir, patient, tp)\n",
    "    t2f_path = find_first_matching_file(tp_path, SEQ_KEYWORDS)\n",
    "    if t2f_path is None: raise FileNotFoundError(f\"[t2f introuvable] {patient}/{tp}\")\n",
    "    vol, affine = load_nifti(t2f_path)\n",
    "\n",
    "    mask_path = find_first_matching_file(tp_path, MASK_KEYWORDS)\n",
    "    if mask_path is None: raise FileNotFoundError(f\"[mask introuvable] {patient}/{tp}\")\n",
    "    mask, _ = load_nifti(mask_path)\n",
    "\n",
    "    vol = vol.astype(np.float32, copy=False)\n",
    "    vol = (vol - vol.mean()) / (vol.std() + 1e-8)\n",
    "    vol = vol[None, ...]\n",
    "    mask = (mask > 0).astype(np.float32)[None, ...]\n",
    "\n",
    "    vol, _  = pad_to_multiple(vol, multiple=8)\n",
    "    mask, _ = pad_to_multiple(mask, multiple=8)\n",
    "    affine = np.asarray(affine, dtype=np.float64)\n",
    "    return vol, mask, affine\n",
    "\n",
    "class AEDataset(Dataset):\n",
    "    def __init__(self, dataset_dir: str, pairs_for_ae: List[Tuple[str,str]], noise_std=(0.05, 0.15)):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.pairs = list(pairs_for_ae)\n",
    "        self.noise_std = noise_std\n",
    "    def __len__(self): return len(self.pairs)\n",
    "    def __getitem__(self, idx):\n",
    "        patient, tp = self.pairs[idx]\n",
    "        vol, _, _ = load_volume_and_mask(self.dataset_dir, patient, tp)\n",
    "        clean = vol\n",
    "        sigma = np.random.uniform(self.noise_std[0], self.noise_std[1])\n",
    "        noisy = clean + sigma * np.random.randn(*clean.shape).astype(np.float32)\n",
    "        return torch.from_numpy(noisy), torch.from_numpy(clean)\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, dataset_dir: str, triples: List[Tuple[str,str,str]]):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.triples = list(triples)  # (patient, tp1, tp2, tp3)\n",
    "    def __len__(self): return len(self.triples)\n",
    "    def __getitem__(self, idx):\n",
    "        patient, tp1, tp2, tp3 = self.triples[idx]\n",
    "        vol1, _, _ = load_volume_and_mask(self.dataset_dir, patient, tp1)\n",
    "        vol2, _, _ = load_volume_and_mask(self.dataset_dir, patient, tp2)\n",
    "        _, mask3, affine3 = load_volume_and_mask(self.dataset_dir, patient, tp3)\n",
    "        x1 = torch.from_numpy(vol1)\n",
    "        x2 = torch.from_numpy(vol2)\n",
    "        y3 = torch.from_numpy(mask3)\n",
    "        return (x1, x2, y3, affine3, (patient, tp3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb464a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Models ===\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.InstanceNorm3d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.InstanceNorm3d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x): return self.block(x)\n",
    "\n",
    "class Encoder3D(nn.Module):\n",
    "    def __init__(self, in_ch=1, base=16):\n",
    "        super().__init__()\n",
    "        self.enc1 = DoubleConv(in_ch, base)\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "        self.enc2 = DoubleConv(base, base*2)\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "        self.bottleneck = DoubleConv(base*2, base*4)\n",
    "        self.out_channels = base*4\n",
    "    def forward(self, x):\n",
    "        x = self.enc1(x); x = self.pool1(x)\n",
    "        x = self.enc2(x); x = self.pool2(x)\n",
    "        z = self.bottleneck(x)\n",
    "        return z\n",
    "\n",
    "class Decoder3D(nn.Module):\n",
    "    def __init__(self, out_ch=1, base=16):\n",
    "        super().__init__()\n",
    "        self.up2 = nn.ConvTranspose3d(base*4, base*2, 2, stride=2)\n",
    "        self.dec2 = DoubleConv(base*2, base*2)\n",
    "        self.up1 = nn.ConvTranspose3d(base*2, base, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(base, base)\n",
    "        self.out_conv = nn.Conv3d(base, out_ch, 1)\n",
    "    def forward(self, z):\n",
    "        x = self.up2(z); x = self.dec2(x)\n",
    "        x = self.up1(x); x = self.dec1(x)\n",
    "        y = self.out_conv(x)\n",
    "        return y\n",
    "\n",
    "class DAE3D(nn.Module):\n",
    "    def __init__(self, in_ch=1, base=16):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder3D(in_ch=in_ch, base=base)\n",
    "        self.decoder = Decoder3D(out_ch=in_ch, base=base)\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x); rec = self.decoder(z); return rec, z\n",
    "\n",
    "class ConvLSTMCell3D(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size=3):\n",
    "        super().__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.conv = nn.Conv3d(input_dim + hidden_dim, 4*hidden_dim, kernel_size, padding=padding)\n",
    "        self.hidden_dim = hidden_dim\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        gates = self.conv(torch.cat([x, h_prev], dim=1))\n",
    "        i, f, g, o = torch.chunk(gates, 4, dim=1)\n",
    "        i, f, o = torch.sigmoid(i), torch.sigmoid(f), torch.sigmoid(o)\n",
    "        g = torch.tanh(g)\n",
    "        c = f * c_prev + i * g\n",
    "        h = o * torch.tanh(c)\n",
    "        return h, c\n",
    "\n",
    "class TemporalSegNet(nn.Module):\n",
    "    def __init__(self, encoder: Encoder3D, hidden_dim=None, base=16):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        enc_out = encoder.out_channels\n",
    "        hidden_dim = hidden_dim or enc_out\n",
    "        self.lstm = ConvLSTMCell3D(input_dim=enc_out, hidden_dim=hidden_dim, kernel_size=3)\n",
    "        self.decoder = Decoder3D(out_ch=1, base=base)\n",
    "    def forward(self, x1, x2):\n",
    "        z1 = self.encoder(x1); z2 = self.encoder(x2)\n",
    "        h = torch.zeros_like(z1); c = torch.zeros_like(z1)\n",
    "        h, c = self.lstm(z1, h, c)\n",
    "        h, c = self.lstm(z2, h, c)\n",
    "        logits = self.decoder(h)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Loss & metric ===\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6): super().__init__(); self.eps = eps\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        inter = (probs * targets).sum(dim=(2,3,4))\n",
    "        union = probs.sum(dim=(2,3,4)) + targets.sum(dim=(2,3,4))\n",
    "        dice = (2*inter + self.eps) / (union + self.eps)\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "def dice_coefficient_from_logits(logits, targets, thr=0.5, eps=1e-6):\n",
    "    probs = torch.sigmoid(logits); preds = (probs > thr).float()\n",
    "    inter = (preds * targets).sum(dim=(2,3,4))\n",
    "    union = preds.sum(dim=(2,3,4)) + targets.sum(dim=(2,3,4))\n",
    "    return ((2*inter + eps) / (union + eps)).mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6185ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Training loops ===\n",
    "def train_ae(model, loader, device, optimizer, epochs=5):\n",
    "    model.train(); l1 = nn.L1Loss(); best_loss = float('inf')\n",
    "    for ep in range(1, epochs+1):\n",
    "        running = 0.0\n",
    "        for noisy, clean in tqdm(loader, desc=f\"AE Train {ep}/{epochs}\"):\n",
    "            noisy, clean = noisy.to(device, non_blocking=True), clean.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad(); rec, _ = model(noisy); loss = l1(rec, clean)\n",
    "            loss.backward(); optimizer.step(); running += loss.item() * noisy.size(0)\n",
    "        avg = running / max(1, len(loader.dataset))\n",
    "        print(f\"[AE] Epoch {ep}/{epochs} - L1: {avg:.4f}\")\n",
    "        if avg < best_loss: best_loss = avg\n",
    "    return best_loss\n",
    "\n",
    "def train_temporal(model, loader, device, optimizer, epochs=10, lambda_bce=0.5):\n",
    "    model.train(); dice_loss = DiceLoss(); bce = nn.BCEWithLogitsLoss()\n",
    "    for ep in range(1, epochs+1):\n",
    "        running = 0.0\n",
    "        for x1, x2, y3, _, _ in tqdm(loader, desc=f\"Seg Train {ep}/{epochs}\"):\n",
    "            x1, x2, y3 = x1.to(device, non_blocking=True), x2.to(device, non_blocking=True), y3.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad(); logits = model(x1, x2)\n",
    "            loss = dice_loss(logits, y3) + lambda_bce * bce(logits, y3)\n",
    "            loss.backward(); optimizer.step(); running += loss.item() * x1.size(0)\n",
    "        avg = running / max(1, len(loader.dataset))\n",
    "        print(f\"[SEG] Epoch {ep}/{epochs} - Loss: {avg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2604f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Inférence robuste & sauvegarde des masques (mise à jour) ===\n",
    "def inference_and_save_temporal(model, loader, device, out_dir):\n",
    "    import os, numpy as np, torch, nibabel as nib\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    model.eval()\n",
    "\n",
    "    def get_meta_pair(metas, i, B):\n",
    "        if isinstance(metas, (list, tuple)) and len(metas) == 2 and \\\n",
    "           all(isinstance(x, (list, tuple, np.ndarray)) for x in metas):\n",
    "            patients, tps = metas\n",
    "            if len(patients) != len(tps):\n",
    "                raise ValueError(f\"metas incohérent: len(patients)={len(patients)} != len(tps)={len(tps)}\")\n",
    "            if i >= len(patients):\n",
    "                raise IndexError(f\"i={i} hors plage pour metas pair-of-lists (taille {len(patients)}), batch B={B}\")\n",
    "            return patients[i], tps[i]\n",
    "        if isinstance(metas, (list, tuple)) and len(metas) > 0 and isinstance(metas[0], (list, tuple)) and len(metas[0]) == 2:\n",
    "            if i >= len(metas):\n",
    "                raise IndexError(f\"i={i} hors plage pour metas list-of-pairs (taille {len(metas)}), batch B={B}\")\n",
    "            return metas[i][0], metas[i][1]\n",
    "        if isinstance(metas, (list, tuple)) and len(metas) == 2 and not any(isinstance(x, (list, tuple)) for x in metas):\n",
    "            return metas[0], metas[1]\n",
    "        if isinstance(metas, (list, tuple)) and len(metas) > 0 and isinstance(metas[0], str):\n",
    "            who = metas[i if i < len(metas) else -1]; s = who.replace('\\\\', '/').split('/')\n",
    "            if len(s) >= 2: return s[-2], s[-1]\n",
    "        if isinstance(metas, str):\n",
    "            s = metas.replace('\\\\', '/').split('/')\n",
    "            if len(s) >= 2: return s[-2], s[-1]\n",
    "        raise ValueError(f\"Format metas non supporté: {type(metas)} | exemple={repr(metas)[:200]}\")\n",
    "\n",
    "    def get_affine_i(affines, i):\n",
    "        if isinstance(affines, torch.Tensor):\n",
    "            a = affines[i] if affines.ndim == 3 else affines\n",
    "            a = a.detach().cpu().numpy()\n",
    "        elif isinstance(affines, np.ndarray):\n",
    "            a = affines[i] if affines.ndim == 3 else affines\n",
    "        elif isinstance(affines, (list, tuple)):\n",
    "            a = affines[i] if len(affines) > 1 else affines[0]; a = np.asarray(a)\n",
    "        else:\n",
    "            a = np.asarray(affines)\n",
    "        a = np.asarray(a, dtype=np.float64)\n",
    "        if a.shape != (4, 4):\n",
    "            raise ValueError(f\"Affine devrait être (4,4), reçu {a.shape}\")\n",
    "        return a\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Inference'):\n",
    "            x1, x2, y3, affines, metas = batch\n",
    "            x1 = x1.to(device, non_blocking=True)\n",
    "            x2 = x2.to(device, non_blocking=True)\n",
    "            logits = model(x1, x2)\n",
    "            probs  = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "            B = probs.shape[0]\n",
    "            for i in range(B):\n",
    "                pred = (probs[i, 0] > 0.5).astype(np.uint8)\n",
    "                patient, tp3 = get_meta_pair(metas, i, B)\n",
    "                affine = get_affine_i(affines, i)\n",
    "                out_path = os.path.join(out_dir, patient, tp3, 'pred_mask.nii.gz')\n",
    "                os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "                nib.save(nib.Nifti1Image(pred.astype(np.uint8), affine), out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033cbdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Paramètres & préparation des DataLoaders ===\n",
    "DATASET_DIR = r'/home/perfect/Documents/GitHub/projet-AI/data_t2f'\n",
    "OUTPUT_DIR  = r'/home/perfect/Documents/GitHub/projet-AI/partie2_outputs'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE_AE  = 1\n",
    "BATCH_SIZE_SEG = 1\n",
    "EPOCHS_AE = 3\n",
    "EPOCHS_SEG = 5\n",
    "LR_AE = 1e-4\n",
    "LR_SEG = 1e-4\n",
    "BASE = 16\n",
    "\n",
    "patients_tps = {}\n",
    "for p in sorted(os.listdir(DATASET_DIR)):\n",
    "    ppath = os.path.join(DATASET_DIR, p)\n",
    "    if not os.path.isdir(ppath): continue\n",
    "    tps = sorted([d for d in os.listdir(ppath) if os.path.isdir(os.path.join(ppath, d))])\n",
    "    if len(tps) >= 3: patients_tps[p] = tps\n",
    "\n",
    "triples = []\n",
    "for p, tps in patients_tps.items():\n",
    "    if len(tps) >= 3: triples.append((p, tps[0], tps[1], tps[2]))\n",
    "\n",
    "patients = sorted(list(patients_tps.keys()))\n",
    "n_train = max(1, int(0.8 * len(patients)))\n",
    "train_patients = set(patients[:n_train])\n",
    "test_patients  = set(patients[n_train:])\n",
    "\n",
    "train_triples = [t for t in triples if t[0] in train_patients]\n",
    "test_triples  = [t for t in triples if t[0] in test_patients]\n",
    "\n",
    "ae_pairs = []\n",
    "for p in train_patients:\n",
    "    tps = patients_tps[p]\n",
    "    if len(tps) >= 2:\n",
    "        ae_pairs.append((p, tps[0])); ae_pairs.append((p, tps[1]))\n",
    "\n",
    "ae_loader = DataLoader(AEDataset(DATASET_DIR, ae_pairs, noise_std=(0.05, 0.15)),\n",
    "                       batch_size=BATCH_SIZE_AE, shuffle=True,\n",
    "                       num_workers=2, pin_memory=torch.cuda.is_available(), persistent_workers=True)\n",
    "\n",
    "train_seq_loader = DataLoader(SequenceDataset(DATASET_DIR, train_triples),\n",
    "                              batch_size=BATCH_SIZE_SEG, shuffle=True,\n",
    "                              num_workers=2, pin_memory=torch.cuda.is_available(), persistent_workers=True)\n",
    "test_seq_loader  = DataLoader(SequenceDataset(DATASET_DIR, test_triples),\n",
    "                              batch_size=1, shuffle=False,\n",
    "                              num_workers=2, pin_memory=torch.cuda.is_available(), persistent_workers=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)\n",
    "print(f\"Train triples: {len(train_triples)} | Test triples: {len(test_triples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddfa957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Stage A : entraînement AutoEncoder 3D ===\n",
    "dae = DAE3D(in_ch=1, base=BASE).to(device)\n",
    "opt_ae = optim.Adam(dae.parameters(), lr=LR_AE)\n",
    "best_l1 = train_ae(dae, ae_loader, device, opt_ae, epochs=EPOCHS_AE)\n",
    "print(\"[AE] Meilleure L1:\", best_l1)\n",
    "AE_CKPT = os.path.join(OUTPUT_DIR, \"dae_best.pt\")\n",
    "torch.save(dae.state_dict(), AE_CKPT)\n",
    "print(\"[AE] Checkpoint sauvegardé:\", AE_CKPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f84015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Stage B : ConvLSTM pour la prédiction TP3 ===\n",
    "encoder = Encoder3D(in_ch=1, base=BASE).to(device)\n",
    "encoder.load_state_dict(dae.encoder.state_dict())\n",
    "for p in encoder.parameters(): p.requires_grad = False\n",
    "\n",
    "model = TemporalSegNet(encoder=encoder, hidden_dim=encoder.out_channels, base=BASE).to(device)\n",
    "opt_seg = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR_SEG)\n",
    "train_temporal(model, train_seq_loader, device, opt_seg, epochs=EPOCHS_SEG, lambda_bce=0.5)\n",
    "\n",
    "SEG_CKPT = os.path.join(OUTPUT_DIR, \"temporal_seg_best.pt\")\n",
    "torch.save(model.state_dict(), SEG_CKPT)\n",
    "print(\"[SEG] Checkpoint sauvegardé:\", SEG_CKPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bac37b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Évaluation Dice (test) ===\n",
    "model.eval(); dice_list = []\n",
    "with torch.no_grad():\n",
    "    for x1, x2, y3, _, _ in tqdm(test_seq_loader, desc=\"Test Eval\"):\n",
    "        x1, x2, y3 = x1.to(device, non_blocking=True), x2.to(device, non_blocking=True), y3.to(device, non_blocking=True)\n",
    "        logits = model(x1, x2)\n",
    "        dice_list.append(dice_coefficient_from_logits(logits, y3, thr=0.5))\n",
    "mean_dice = float(np.mean(dice_list)) if dice_list else float('nan')\n",
    "print(f\"[TEST] Mean Dice (TP3): {mean_dice:.4f} over {len(dice_list)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd662d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Inférence & sauvegarde dans output_masks/ ===\n",
    "OUT_MASKS_DIR = os.path.join(OUTPUT_DIR, \"output_masks\")\n",
    "os.makedirs(OUT_MASKS_DIR, exist_ok=True)\n",
    "# model.load_state_dict(torch.load(SEG_CKPT, map_location=device))  # si besoin\n",
    "inference_and_save_temporal(model, test_seq_loader, device, OUT_MASKS_DIR)\n",
    "print(\"[OK] Masques prédits sauvés dans:\", OUT_MASKS_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
