{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c85a41",
   "metadata": {},
   "source": [
    "# Segmentation 3D — Notebook\n",
    "\n",
    "Ce notebook contient un pipeline complet et commenté pour segmenter des tumeurs 3D à partir de volumes `.nii.gz`.\n",
    "\n",
    "**Organisation**:\n",
    "- Entraînement: Timepoint_1 + Timepoint_2\n",
    "- Test: Timepoint_3\n",
    "\n",
    "> Adapté pour usage avec MedSegDiff-V2 (si disponible) ou fallback UNet3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c373d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Setup - imports et paramètres\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Séquences et nom de masque\n",
    "SEQUENCES = [\"t1c\", \"t2f\", \"t2w\"]\n",
    "MASK_NAME = \"tumorMask\"\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed767d5",
   "metadata": {},
   "source": [
    "## Fonctions utilitaires\n",
    "\n",
    "Chargement/sauvegarde NIfTI et fonctions de visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555acc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "def load_nifti(path):\n",
    "    \"\"\"Charge un fichier NIfTI et retourne (data_float32, affine).\"\"\"\n",
    "    img = nib.load(path)\n",
    "    return img.get_fdata(dtype=np.float32), img.affine\n",
    "\n",
    "def save_nifti(data, affine, out_path):\n",
    "    \"\"\"Sauvegarde data (numpy) au format NIfTI en gardant affine.\"\"\"\n",
    "    img = nib.Nifti1Image(data.astype(np.float32), affine)\n",
    "    nib.save(img, out_path)\n",
    "\n",
    "def find_sequence_file(tp_dir, seq_key):\n",
    "    \"\"\"Retourne le chemin d'un fichier dans tp_dir contenant seq_key dans son nom (ou None).\"\"\"\n",
    "    for f in os.listdir(tp_dir):\n",
    "        if seq_key in f and (f.endswith('.nii') or f.endswith('.nii.gz')):\n",
    "            return os.path.join(tp_dir, f)\n",
    "    return None\n",
    "\n",
    "def show_slices(imgs, masks=None, slice_idx=None, figsize=(12,6)):\n",
    "    \"\"\"Affiche des slices (axial) côte-à-côte pour chaque canal et le masque si fourni.\"\"\"\n",
    "    # imgs : numpy array (C, D, H, W) or (D,H,W)\n",
    "    if imgs.ndim == 4:\n",
    "        C, D, H, W = imgs.shape\n",
    "    elif imgs.ndim == 3:\n",
    "        C = 1\n",
    "        D, H, W = imgs.shape\n",
    "        imgs = imgs[None, ...]\n",
    "    if slice_idx is None:\n",
    "        slice_idx = D // 2\n",
    "    ncols = C + (1 if masks is not None else 0)\n",
    "    fig, axes = plt.subplots(1, ncols, figsize=figsize)\n",
    "    for c in range(C):\n",
    "        ax = axes[c] if ncols>1 else axes\n",
    "        im = imgs[c, slice_idx, :, :]\n",
    "        ax.imshow(im.T, cmap='gray', origin='lower')\n",
    "        ax.set_title(f'Canal {c} - slice {slice_idx}')\n",
    "        ax.axis('off')\n",
    "    if masks is not None:\n",
    "        m = masks if masks.ndim==3 else masks[0]\n",
    "        ax = axes[-1]\n",
    "        ax.imshow(m[slice_idx].T, cmap='gray', origin='lower')\n",
    "        ax.set_title('Masque')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f27c4",
   "metadata": {},
   "source": [
    "## Dataset PyTorch\n",
    "\n",
    "Classe Dataset qui charge les échantillons en respectant la règle : utiliser Timepoint_1 et Timepoint_2 pour l'entraînement et Timepoint_3 pour le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ddc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "class MRIDataset3D(Dataset):\n",
    "    \"\"\"Dataset PyTorch pour volumes multi-séquences.\n",
    "    Retourne: (image_tensor, mask_tensor, affine, (patient, timepoint))\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_dir, patients, timepoints, sequences=SEQUENCES):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.patients = patients\n",
    "        self.timepoints = timepoints\n",
    "        self.sequences = sequences\n",
    "        self.samples = []\n",
    "        for patient in patients:\n",
    "            for tp in timepoints:\n",
    "                tp_path = os.path.join(dataset_dir, patient, tp)\n",
    "                if os.path.isdir(tp_path):\n",
    "                    # Vérifier que toutes les séquences et le masque existent\n",
    "                    ok = True\n",
    "                    for s in sequences + [MASK_NAME]:\n",
    "                        if find_sequence_file(tp_path, s) is None:\n",
    "                            ok = False\n",
    "                            break\n",
    "                    if ok:\n",
    "                        self.samples.append((patient, tp))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def pad_to_multiple(vol, multiple=8):\n",
    "        \"\"\"Pad numpy array 3D or 4D (C,D,H,W) so that D,H,W are multiples of 'multiple'.\"\"\"\n",
    "        if vol.ndim == 4:\n",
    "            C, D, H, W = vol.shape\n",
    "            pad_D = (multiple - D % multiple) if D % multiple != 0 else 0\n",
    "            pad_H = (multiple - H % multiple) if H % multiple != 0 else 0\n",
    "            pad_W = (multiple - W % multiple) if W % multiple != 0 else 0\n",
    "            return np.pad(vol, ((0,0),(0,pad_D),(0,pad_H),(0,pad_W)), mode='constant'), (pad_D,pad_H,pad_W)\n",
    "        elif vol.ndim == 3:\n",
    "            D, H, W = vol.shape\n",
    "            pad_D = (multiple - D % multiple) if D % multiple != 0 else 0\n",
    "            pad_H = (multiple - H % multiple) if H % multiple != 0 else 0\n",
    "            pad_W = (multiple - W % multiple) if W % multiple != 0 else 0\n",
    "            return np.pad(vol, ((0,pad_D),(0,pad_H),(0,pad_W)), mode='constant'), (pad_D,pad_H,pad_W)\n",
    "        else:\n",
    "            return vol, (0,0,0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient, tp = self.samples[idx]\n",
    "        tp_path = os.path.join(self.dataset_dir, patient, tp)\n",
    "        channels = []\n",
    "        affine = None\n",
    "        for seq in self.sequences:\n",
    "            p = find_sequence_file(tp_path, seq)\n",
    "            data, a = load_nifti(p)\n",
    "            if affine is None:\n",
    "                affine = a\n",
    "            # z-score normalisation\n",
    "            data = (data - np.mean(data)) / (np.std(data) + 1e-8)\n",
    "            channels.append(data)\n",
    "        mask_p = find_sequence_file(tp_path, MASK_NAME)\n",
    "        mask, _ = load_nifti(mask_p)\n",
    "        mask = (mask > 0).astype(np.float32)\n",
    "        vol = np.stack(channels, axis=0)  # (C, D, H, W)\n",
    "        mask = mask[None, ...]            # (1, D, H, W)\n",
    "        vol, _ = pad_to_multiple(vol, multiple=8)\n",
    "        mask, _ = pad_to_multiple(mask, multiple=8)\n",
    "        return torch.from_numpy(vol.astype(np.float32)), torch.from_numpy(mask.astype(np.float32)), affine, (patient, tp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ca91f0",
   "metadata": {},
   "source": [
    "## Modèle UNet3D (fallback)\n",
    "\n",
    "Architecture UNet3D simple commentée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd78eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, 3, padding=1), nn.BatchNorm3d(out_ch), nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_ch, out_ch, 3, padding=1), nn.BatchNorm3d(out_ch), nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=1, base_filters=16):\n",
    "        super().__init__()\n",
    "        f = base_filters\n",
    "        self.enc1 = DoubleConv(in_ch, f)\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        self.enc2 = DoubleConv(f, f*2)\n",
    "        self.enc3 = DoubleConv(f*2, f*4)\n",
    "        self.bottleneck = DoubleConv(f*4, f*8)\n",
    "        self.up3 = nn.ConvTranspose3d(f*8, f*4, 2, stride=2)\n",
    "        self.dec3 = DoubleConv(f*8, f*4)\n",
    "        self.up2 = nn.ConvTranspose3d(f*4, f*2, 2, stride=2)\n",
    "        self.dec2 = DoubleConv(f*4, f*2)\n",
    "        self.up1 = nn.ConvTranspose3d(f*2, f, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(f*2, f)\n",
    "        self.outc = nn.Conv3d(f, out_ch, 1)\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        b = self.bottleneck(self.pool(e3))\n",
    "        d3 = self.up3(b)\n",
    "        d3 = self.dec3(torch.cat([d3, e3], dim=1))\n",
    "        d2 = self.up2(d3)\n",
    "        d2 = self.dec2(torch.cat([d2, e2], dim=1))\n",
    "        d1 = self.up1(d2)\n",
    "        d1 = self.dec1(torch.cat([d1, e1], dim=1))\n",
    "        return self.outc(d1)\n",
    "\n",
    "# Dice loss\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "    def forward(self, logits, target):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        inter = (probs * target).sum(dim=[1,2,3,4])\n",
    "        denom = probs.sum(dim=[1,2,3,4]) + target.sum(dim=[1,2,3,4])\n",
    "        return 1 - ((2*inter + self.eps) / (denom + self.eps)).mean()\n",
    "\n",
    "def dice_coef(logits, target, eps=1e-6):\n",
    "    pred = (torch.sigmoid(logits) > 0.5).float()\n",
    "    inter = (pred * target).sum(dim=[1,2,3,4])\n",
    "    denom = pred.sum(dim=[1,2,3,4]) + target.sum(dim=[1,2,3,4])\n",
    "    return ((2*inter + eps) / (denom + eps)).mean().item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee724d5",
   "metadata": {},
   "source": [
    "## Entraînement\n",
    "\n",
    "Boucles d'entraînement et d'évaluation. Entraîne sur Timepoint_1+Timepoint_2 et évalue sur Timepoint_3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32480571",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "def train_epoch(model, loader, device, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for imgs, masks, _, _ in tqdm(loader, desc='Train'):\n",
    "        imgs = imgs.to(device)\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def eval_epoch(model, loader, device, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_dice = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks, _, _ in tqdm(loader, desc='Eval'):\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, masks)\n",
    "            total_loss += loss.item()\n",
    "            total_dice += dice_coef(logits, masks)\n",
    "    return total_loss / len(loader), total_dice / len(loader)\n",
    "\n",
    "def inference_and_save(model, loader, device, out_dir):\n",
    "    model.eval()\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks, affines, metas in tqdm(loader, desc='Infer'):\n",
    "            imgs = imgs.to(device)\n",
    "            logits = model(imgs)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            for i in range(probs.shape[0]):\n",
    "                pred = (probs[i,0] > 0.5).astype(np.uint8)\n",
    "                patient, tp = metas[i]\n",
    "                out_path = os.path.join(out_dir, patient, tp, 'pred_mask.nii.gz')\n",
    "                os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "                save_nifti(pred, affines[i], out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1937cbd7",
   "metadata": {},
   "source": [
    "## Exemple d'exécution\n",
    "\n",
    "Modifie `DATASET_DIR` et exécute cette cellule pour lancer l'entraînement (GPU recommandé)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797397f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres à éditer par l'utilisateur\n",
    "DATASET_DIR = '/home/perfect/Documents/GitHub/projet-AI/data_filter'   # <-- change\n",
    "OUTPUT_DIR = '/home/perfect/Documents/GitHub/projet-AI/data_segmentation'      # <-- change\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 20\n",
    "LR = 1e-4\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, 'predictions'), exist_ok=True)\n",
    "\n",
    "# Lister patients ayant >=3 timepoints et prendre les 3 premiers\n",
    "patients_timepoints = {}\n",
    "for p in sorted(os.listdir(DATASET_DIR)):\n",
    "    ppath = os.path.join(DATASET_DIR, p)\n",
    "    if not os.path.isdir(ppath):\n",
    "        continue\n",
    "    tps = sorted([d for d in os.listdir(ppath) if os.path.isdir(os.path.join(ppath, d))])\n",
    "    if len(tps) >= 3:\n",
    "        patients_timepoints[p] = tps[:3]\n",
    "\n",
    "print(f\"Patients retenus: {len(patients_timepoints)}\")\n",
    "\n",
    "# Datasets: train = TP1+TP2, test = TP3\n",
    "train_patients = list(patients_timepoints.keys())\n",
    "train_tp1 = [patients_timepoints[p][0] for p in train_patients]\n",
    "train_tp2 = [patients_timepoints[p][1] for p in train_patients]\n",
    "test_tp3  = [patients_timepoints[p][2] for p in train_patients]\n",
    "\n",
    "# Fusionner Timepoint 1 et 2 pour l'entraînement\n",
    "train_ds = MRIDataset3D(DATASET_DIR, train_patients, train_tp1 + train_tp2)\n",
    "test_ds  = MRIDataset3D(DATASET_DIR, train_patients, test_tp3)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet3D(in_ch=len(SEQUENCES), out_ch=1).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = DiceLoss()\n",
    "\n",
    "best_dice = 0.0\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_loss = train_epoch(model, train_loader, device, optimizer, criterion)\n",
    "    val_loss, val_dice = eval_epoch(model, test_loader, device, criterion)\n",
    "    print(f'Epoch {epoch}/{EPOCHS} - Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}')\n",
    "    # Save best model\n",
    "    if val_dice > best_dice:\n",
    "        best_dice = val_dice\n",
    "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'best_model.pt'))\n",
    "        print('Best model saved.')\n",
    "\n",
    "# Inference and save\n",
    "inference_and_save(model, test_loader, device, os.path.join(OUTPUT_DIR, 'predictions'))\n",
    "print('Done. Predictions saved to', os.path.join(OUTPUT_DIR, 'predictions'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908d33b",
   "metadata": {},
   "source": [
    "## Visualisation des résultats\n",
    "\n",
    "Affiche des slices (axial) des volumes et des masques (vérité terrain et prédiction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc17b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Exemple pour visualiser un patient/timepoint précis (après inférence)\n",
    "def visualize_patient_timepoint(data_root, patient, timepoint, pred_root=None, slice_idx=None):\n",
    "    tp_path = os.path.join(data_root, patient, timepoint)\n",
    "    channels = []\n",
    "    for seq in SEQUENCES:\n",
    "        f = find_sequence_file(tp_path, seq)\n",
    "        d, _ = load_nifti(f)\n",
    "        channels.append(d)\n",
    "    vol = np.stack(channels, axis=0)\n",
    "    mask_f = find_sequence_file(tp_path, MASK_NAME)\n",
    "    mask, _ = load_nifti(mask_f)\n",
    "    pred_mask = None\n",
    "    if pred_root:\n",
    "        pred_p = os.path.join(pred_root, patient, timepoint, 'pred_mask.nii.gz')\n",
    "        if os.path.exists(pred_p):\n",
    "            pred_mask, _ = load_nifti(pred_p)\n",
    "    show_slices(vol, masks=pred_mask if pred_mask is not None else mask, slice_idx=slice_idx)\n",
    "\n",
    "# Usage example (modifier les chemins et ids)\n",
    "# visualize_patient_timepoint(DATASET_DIR, 'PatientID_0162', 'Timepoint_3', pred_root=os.path.join(OUTPUT_DIR,'predictions'))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
