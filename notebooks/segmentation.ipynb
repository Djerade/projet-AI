{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "52346d54",
      "metadata": {
        "id": "52346d54"
      },
      "source": [
        "# Segmentation 3D — t2f-only (FLAIR) avec cache NPZ\n",
        "Notebook autonome prêt à exécuter : dataset basé sur **paires (patient, timepoint)**, **cache** pour accélérer, DataLoaders avec **num_workers=2**, et inférence robuste."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cYTjS-aOV-l",
        "outputId": "f2dc8dda-5cdb-4c6a-e7f1-d7b521a4daa4"
      },
      "id": "4cYTjS-aOV-l",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dc9eff8e",
      "metadata": {
        "id": "dc9eff8e"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os, re, json\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "10cb53c2",
      "metadata": {
        "id": "10cb53c2"
      },
      "outputs": [],
      "source": [
        "# Utils: pad & NIfTI loader (signature: (data, affine))\n",
        "def pad_to_multiple(volume, multiple=8, mode='constant', value=0):\n",
        "    \"\"\"Pad 3D/4D array so spatial dims are multiples of `multiple`.\n",
        "    Returns (padded_volume, pad_widths).\"\"\"\n",
        "    if volume.ndim == 3:\n",
        "        shape = volume.shape\n",
        "        pad_widths = []\n",
        "        for dim in shape:\n",
        "            r = dim % multiple\n",
        "            pad_widths.append((0, 0 if r == 0 else multiple - r))\n",
        "        return np.pad(volume, pad_widths, mode=mode, constant_values=value), pad_widths\n",
        "    elif volume.ndim == 4:\n",
        "        shape = volume.shape[1:]\n",
        "        pad_widths = [(0,0)]\n",
        "        for dim in shape:\n",
        "            r = dim % multiple\n",
        "            pad_widths.append((0, 0 if r == 0 else multiple - r))\n",
        "        return np.pad(volume, pad_widths, mode=mode, constant_values=value), pad_widths\n",
        "    else:\n",
        "        raise ValueError(\"Volume must be 3D or 4D\")\n",
        "\n",
        "def load_nifti(path):\n",
        "    img = nib.load(path)\n",
        "    data = img.get_fdata()\n",
        "    return data, img.affine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "34bf1ae4",
      "metadata": {
        "id": "34bf1ae4"
      },
      "outputs": [],
      "source": [
        "# Recherche robuste des fichiers (t2f_processed & tumorMask)\n",
        "from typing import List, Optional\n",
        "\n",
        "SEQ_KEYWORDS  = [\"t2f_processed\", \"t2f\", \"flair\", \"t2_flair\", \"t2fla\"]\n",
        "MASK_KEYWORDS = [\"tumorMask\", \"mask\", \"seg\", \"label\"]\n",
        "\n",
        "def is_nifti(fname: str) -> bool:\n",
        "    low = fname.lower()\n",
        "    return low.endswith(\".nii\") or low.endswith(\".nii.gz\")\n",
        "\n",
        "def find_first_matching_file(folder: str, keywords: List[str]) -> Optional[str]:\n",
        "    keys = [k.lower() for k in keywords]\n",
        "    for fname in sorted(os.listdir(folder)):\n",
        "        if not is_nifti(fname):\n",
        "            continue\n",
        "        low = fname.lower()\n",
        "        if any(k in low for k in keys):\n",
        "            return os.path.join(folder, fname)\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "75b36d0a",
      "metadata": {
        "id": "75b36d0a"
      },
      "outputs": [],
      "source": [
        "# Modèle UNet 3D (simple) — in_ch=1, out_ch=1\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv3d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.InstanceNorm3d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.InstanceNorm3d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    def __init__(self, in_ch=1, out_ch=1):\n",
        "        super().__init__()\n",
        "        f = 16\n",
        "        self.down1 = DoubleConv(in_ch, f)\n",
        "        self.pool1 = nn.MaxPool3d(2)\n",
        "        self.down2 = DoubleConv(f, f*2)\n",
        "        self.pool2 = nn.MaxPool3d(2)\n",
        "        self.down3 = DoubleConv(f*2, f*4)\n",
        "        self.pool3 = nn.MaxPool3d(2)\n",
        "\n",
        "        self.bottleneck = DoubleConv(f*4, f*8)\n",
        "\n",
        "        self.up3 = nn.ConvTranspose3d(f*8, f*4, 2, stride=2)\n",
        "        self.dec3 = DoubleConv(f*8, f*4)\n",
        "        self.up2 = nn.ConvTranspose3d(f*4, f*2, 2, stride=2)\n",
        "        self.dec2 = DoubleConv(f*4, f*2)\n",
        "        self.up1 = nn.ConvTranspose3d(f*2, f, 2, stride=2)\n",
        "        self.dec1 = DoubleConv(f*2, f)\n",
        "\n",
        "        self.out_conv = nn.Conv3d(f, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        c1 = self.down1(x); p1 = self.pool1(c1)\n",
        "        c2 = self.down2(p1); p2 = self.pool2(c2)\n",
        "        c3 = self.down3(p2); p3 = self.pool3(c3)\n",
        "\n",
        "        b = self.bottleneck(p3)\n",
        "\n",
        "        u3 = self.up3(b); x3 = torch.cat([u3, c3], dim=1); d3 = self.dec3(x3)\n",
        "        u2 = self.up2(d3); x2 = torch.cat([u2, c2], dim=1); d2 = self.dec2(x2)\n",
        "        u1 = self.up1(d2); x1 = torch.cat([u1, c1], dim=1); d1 = self.dec1(x1)\n",
        "        return self.out_conv(d1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8b8585d7",
      "metadata": {
        "id": "8b8585d7"
      },
      "outputs": [],
      "source": [
        "# Dice et loss\n",
        "def dice_coefficient(pred, target, eps=1e-6):\n",
        "    # pred et target en float32 (0..1), taille [B,1,D,H,W]\n",
        "    pred = (pred > 0.5).float()\n",
        "    target = (target > 0.5).float()\n",
        "    inter = (pred * target).sum(dim=(2,3,4))\n",
        "    union = pred.sum(dim=(2,3,4)) + target.sum(dim=(2,3,4))\n",
        "    dice = (2*inter + eps) / (union + eps)\n",
        "    return dice.mean()\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "    def forward(self, logits, targets):\n",
        "        probs = torch.sigmoid(logits)\n",
        "        inter = (probs * targets).sum(dim=(2,3,4))\n",
        "        union = probs.sum(dim=(2,3,4)) + targets.sum(dim=(2,3,4))\n",
        "        dice = (2*inter + self.eps) / (union + self.eps)\n",
        "        return 1 - dice.mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "82dc13c3",
      "metadata": {
        "id": "82dc13c3"
      },
      "outputs": [],
      "source": [
        "# Dataset t2f-only (paires) + cache NPZ\n",
        "class MRIDataset3D(Dataset):\n",
        "    \"\"\"t2f-only. Paires (patient, tp). Cache optionnel (npz).\n",
        "    Retourne: (img[1,D,H,W], mask[1,D,H,W], affine, (patient, tp)).\"\"\"\n",
        "    def __init__(self, dataset_dir, pairs, cache_dir=None, use_cache=True):\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.pairs = list(pairs)\n",
        "        self.cache_dir = cache_dir\n",
        "        self.use_cache = use_cache\n",
        "        if self.cache_dir and self.use_cache:\n",
        "            os.makedirs(self.cache_dir, exist_ok=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        patient, tp = self.pairs[idx]\n",
        "        tp_path = os.path.join(self.dataset_dir, patient, tp)\n",
        "\n",
        "        cache_path = None\n",
        "        if self.cache_dir and self.use_cache:\n",
        "            cache_path = os.path.join(self.cache_dir, f\"{patient}__{tp}.npz\")\n",
        "\n",
        "        if cache_path is not None and os.path.isfile(cache_path):\n",
        "            z = np.load(cache_path)\n",
        "            vol    = z[\"vol\"]      # (1,D,H,W) float32\n",
        "            mask   = z[\"mask\"]     # (1,D,H,W) float32 (0/1)\n",
        "            affine = z[\"affine\"]\n",
        "        else:\n",
        "            # t2f\n",
        "            t2f_path = find_first_matching_file(tp_path, SEQ_KEYWORDS)\n",
        "            if t2f_path is None:\n",
        "                raise FileNotFoundError(f\"[t2f introuvable] {patient}/{tp}\")\n",
        "            vol, affine = load_nifti(t2f_path)\n",
        "\n",
        "            # mask\n",
        "            mask_path = find_first_matching_file(tp_path, MASK_KEYWORDS)\n",
        "            if mask_path is None:\n",
        "                raise FileNotFoundError(f\"[mask introuvable] {patient}/{tp}\")\n",
        "            mask, _ = load_nifti(mask_path)\n",
        "\n",
        "            # prétraitements\n",
        "            vol = vol.astype(np.float32, copy=False)\n",
        "            vol = (vol - vol.mean()) / (vol.std() + 1e-8)\n",
        "            vol = vol[None, ...]  # (1,D,H,W)\n",
        "            mask = (mask > 0).astype(np.float32)[None, ...]  # (1,D,H,W)\n",
        "\n",
        "            vol, _  = pad_to_multiple(vol, multiple=8)\n",
        "            mask, _ = pad_to_multiple(mask, multiple=8)\n",
        "\n",
        "            if cache_path is not None:\n",
        "                np.savez_compressed(cache_path, vol=vol, mask=mask, affine=affine)\n",
        "\n",
        "        # 🔒 assure l'affine en np.float64 (4x4) avant retour\n",
        "        affine = np.asarray(affine, dtype=np.float64)\n",
        "\n",
        "        return (torch.from_numpy(vol), torch.from_numpy(mask), affine, (patient, tp))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4e63078a",
      "metadata": {
        "id": "4e63078a"
      },
      "outputs": [],
      "source": [
        "# Entraînement / évaluation\n",
        "def train_epoch(model, loader, device, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for imgs, masks, _, _ in tqdm(loader, desc=\"Train\"):\n",
        "        imgs  = imgs.to(device, non_blocking=True)\n",
        "        masks = masks.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(imgs)\n",
        "        loss = criterion(logits, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "    return total_loss / max(1, len(loader.dataset))\n",
        "\n",
        "def eval_epoch(model, loader, device, criterion):\n",
        "    model.eval()\n",
        "    total_loss, total_dice, n = 0.0, 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, masks, _, _ in tqdm(loader, desc=\"Val\"):\n",
        "            imgs  = imgs.to(device, non_blocking=True)\n",
        "            masks = masks.to(device, non_blocking=True)\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, masks)\n",
        "            probs = torch.sigmoid(logits)\n",
        "            dice  = dice_coefficient(probs, masks)\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            total_dice += dice.item() * imgs.size(0)\n",
        "            n += imgs.size(0)\n",
        "    return total_loss / max(1,n), total_dice / max(1,n)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "be9548d9",
      "metadata": {
        "id": "be9548d9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Inférence robuste (gère différents formats de metas) + affine (4x4)\n",
        "def inference_and_save(model, loader, device, out_dir):\n",
        "    import numpy as np\n",
        "    import torch, os\n",
        "    import nibabel as nib\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    model.eval()\n",
        "\n",
        "    def get_meta_pair(metas, i):\n",
        "        # ( [patients], [tps] )\n",
        "        if isinstance(metas, (list, tuple)) and len(metas) == 2 and \\\n",
        "           all(isinstance(x, (list, tuple)) for x in metas):\n",
        "            return metas[0][i], metas[1][i]\n",
        "        # [ (patient, tp), ... ]\n",
        "        if isinstance(metas, (list, tuple)) and len(metas) > 0 and \\\n",
        "           isinstance(metas[0], (list, tuple)) and len(metas[0]) == 2:\n",
        "            return metas[i][0], metas[i][1]\n",
        "        # (patient, tp) si B=1\n",
        "        if isinstance(metas, (list, tuple)) and len(metas) == 2 and \\\n",
        "           not any(isinstance(x, (list, tuple)) for x in metas):\n",
        "            return metas[0], metas[1]\n",
        "        # \".../PatientID/Timepoint\" ou \"...\\\\PatientID\\\\Timepoint\"\n",
        "        if isinstance(metas, (list, tuple)) and len(metas) > 0 and isinstance(metas[i], str):\n",
        "            s = metas[i].replace('\\\\', '/').split('/')\n",
        "            if len(s) >= 2:\n",
        "                return s[-2], s[-1]\n",
        "        raise ValueError(f\"Format metas non supporté: type={type(metas)} exemple={metas}\")\n",
        "\n",
        "    def get_affine_i(affines, i):\n",
        "        # torch.Tensor\n",
        "        if isinstance(affines, torch.Tensor):\n",
        "            a = affines[i] if affines.ndim == 3 else affines\n",
        "            a = a.detach().cpu().numpy()\n",
        "        # numpy array\n",
        "        elif isinstance(affines, np.ndarray):\n",
        "            a = affines[i] if affines.ndim == 3 else affines\n",
        "        # list/tuple\n",
        "        elif isinstance(affines, (list, tuple)):\n",
        "            if len(affines) == 0:\n",
        "                raise ValueError(\"Liste d'affines vide\")\n",
        "            a = affines[i] if len(affines) > 1 else affines[0]\n",
        "            a = np.asarray(a)\n",
        "        else:\n",
        "            a = np.asarray(affines)\n",
        "\n",
        "        a = np.asarray(a, dtype=np.float64)\n",
        "        if a.shape != (4, 4):\n",
        "            raise ValueError(f\"Affine devrait être (4,4), reçu {a.shape} (type {type(a)})\")\n",
        "        return a\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc='Inference'):\n",
        "            imgs, _, affines, metas = batch\n",
        "            imgs = imgs.to(device, non_blocking=True)\n",
        "            logits = model(imgs)               # [B,1,D,H,W]\n",
        "            probs  = torch.sigmoid(logits).cpu().numpy()\n",
        "\n",
        "            B = probs.shape[0]\n",
        "            for i in range(B):\n",
        "                pred = (probs[i, 0] > 0.5).astype(np.uint8)\n",
        "                patient, tp = get_meta_pair(metas, i)\n",
        "                affine = get_affine_i(affines, i)\n",
        "\n",
        "                out_path = os.path.join(out_dir, patient, tp, 'pred_mask.nii.gz')\n",
        "                os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "                nib.save(nib.Nifti1Image(pred.astype(np.uint8), affine), out_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dc032296",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc032296",
        "outputId": "09dc7d04-2876-44fa-8351-e580f29e1c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patients retenus (>=2 TP): 3\n",
            "Taille attendue ~ train=6 | test=3\n"
          ]
        }
      ],
      "source": [
        "# Paramètres & DataLoaders (Windows-friendly paths)\n",
        "# ⚠️ Adapte ces chemins à ta machine. Utilise des slashes '/' ou des raw strings r'...'\n",
        "DATASET_DIR = r'/content/drive/MyDrive/Data_test'\n",
        "OUTPUT_DIR  = r'/content/drive/MyDrive/Data_test_segmentation'\n",
        "BATCH_SIZE  = 1\n",
        "EPOCHS      = 20\n",
        "LR          = 1e-4\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, 'predictions'), exist_ok=True)\n",
        "\n",
        "# Cache\n",
        "CACHE_DIR = os.path.join(OUTPUT_DIR, 'cache_npz')\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "# Lister patients et timepoints\n",
        "patients_timepoints = {}\n",
        "for p in sorted(os.listdir(DATASET_DIR)):\n",
        "    ppath = os.path.join(DATASET_DIR, p)\n",
        "    if not os.path.isdir(ppath):\n",
        "        continue\n",
        "    tps = sorted([d for d in os.listdir(ppath) if os.path.isdir(os.path.join(ppath, d))])\n",
        "    if len(tps) >= 3:\n",
        "        patients_timepoints[p] = tps[:3]   # 2 train + 1 test\n",
        "    elif len(tps) == 2:\n",
        "        patients_timepoints[p] = tps       # 1 train + 1 test\n",
        "    # sinon (1 TP): ignore\n",
        "\n",
        "print(f\"Patients retenus (>=2 TP): {len(patients_timepoints)}\")\n",
        "\n",
        "# Paires (patient,tp)\n",
        "train_pairs, test_pairs = [], []\n",
        "for p, tps in patients_timepoints.items():\n",
        "    if len(tps) >= 3:\n",
        "        train_pairs.extend([(p, tps[0]), (p, tps[1])])\n",
        "        test_pairs.append((p, tps[2]))\n",
        "    elif len(tps) == 2:\n",
        "        train_pairs.append((p, tps[0]))\n",
        "        test_pairs.append((p, tps[1]))\n",
        "\n",
        "print(f\"Taille attendue ~ train={len(train_pairs)} | test={len(test_pairs)}\")\n",
        "\n",
        "# Datasets & loaders\n",
        "train_ds = MRIDataset3D(DATASET_DIR, train_pairs, cache_dir=CACHE_DIR, use_cache=True)\n",
        "test_ds  = MRIDataset3D(DATASET_DIR, test_pairs,  cache_dir=CACHE_DIR, use_cache=True)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=2, pin_memory=torch.cuda.is_available(),\n",
        "                          persistent_workers=True)\n",
        "\n",
        "test_loader  = DataLoader(test_ds,  batch_size=1, shuffle=False,\n",
        "                          num_workers=2, pin_memory=torch.cuda.is_available(),\n",
        "                          persistent_workers=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet3D(in_ch=1, out_ch=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = DiceLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "59ff59ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59ff59ea",
        "outputId": "a21c00de-44b9-4716-969d-54864884a001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:19<00:00,  3.27s/it]\n",
            "Val: 100%|██████████| 3/3 [00:03<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n",
            "Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:15<00:00,  2.58s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n",
            "Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:15<00:00,  2.60s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:15<00:00,  2.62s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n",
            "Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:15<00:00,  2.65s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:16<00:00,  2.72s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:16<00:00,  2.70s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:16<00:00,  2.73s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n",
            "Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:16<00:00,  2.79s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:17<00:00,  2.88s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:17<00:00,  2.89s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:16<00:00,  2.82s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n",
            "Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:16<00:00,  2.80s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:16<00:00,  2.81s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:17<00:00,  2.85s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:17<00:00,  2.85s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:17<00:00,  2.85s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n",
            "Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:17<00:00,  2.83s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:17<00:00,  2.87s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 6/6 [00:16<00:00,  2.83s/it]\n",
            "Val: 100%|██████████| 3/3 [00:02<00:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Entraînement + sauvegarde meilleur modèle\n",
        "best_dice = 0.0\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train_loss = train_epoch(model, train_loader, device, optimizer, criterion)\n",
        "    val_loss, val_dice = eval_epoch(model, test_loader, device, criterion)\n",
        "    print(f'Epoch {epoch}/{EPOCHS} - Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}')\n",
        "    if val_dice > best_dice:\n",
        "        best_dice = val_dice\n",
        "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'best_model.pt'))\n",
        "        print('Best model saved.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6be7a540",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6be7a540",
        "outputId": "dc8e1168-f0f1-4285-9eaf-601937b36bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 100%|██████████| 3/3 [00:04<00:00,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Predictions saved to /content/drive/MyDrive/Data_test_segmentation/predictions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Inférence\n",
        "inference_and_save(model, test_loader, device, os.path.join(OUTPUT_DIR, 'predictions'))\n",
        "print('Done. Predictions saved to', os.path.join(OUTPUT_DIR, 'predictions'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Inference-only : charger le modèle entraîné et sauver dans output_masks/ ======\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# 1) Chemins (réutilise OUTPUT_DIR/DATASET_DIR déjà définis plus haut)\n",
        "CHECKPOINT_PATH = os.path.join(OUTPUT_DIR, \"/content/drive/MyDrive/Data_test_segmentation/best_model.pt\")\n",
        "OUT_MASKS_DIR   = os.path.join(OUTPUT_DIR, \"output_masks\")\n",
        "os.makedirs(OUT_MASKS_DIR, exist_ok=True)\n",
        "\n",
        "# 2) Recréer le dataset TEST (patients avec >=2 TP : test = TP3 si dispo, sinon TP2)\n",
        "patients_timepoints = {}\n",
        "for p in sorted(os.listdir(DATASET_DIR)):\n",
        "    ppath = os.path.join(DATASET_DIR, p)\n",
        "    if not os.path.isdir(ppath):\n",
        "        continue\n",
        "    tps = sorted([d for d in os.listdir(ppath) if os.path.isdir(os.path.join(ppath, d))])\n",
        "    if len(tps) >= 3:\n",
        "        patients_timepoints[p] = tps[:3]   # (TP1, TP2, TP3)\n",
        "    elif len(tps) == 2:\n",
        "        patients_timepoints[p] = tps       # (TP1, TP2)\n",
        "    # sinon: ignoré\n",
        "\n",
        "# paires test : 3e si dispo, sinon 2e\n",
        "test_pairs = []\n",
        "for p, tps in patients_timepoints.items():\n",
        "    if len(tps) >= 3:\n",
        "        test_pairs.append((p, tps[2]))\n",
        "    elif len(tps) == 2:\n",
        "        test_pairs.append((p, tps[1]))\n",
        "\n",
        "print(f\"[INFO] Nb paires test: {len(test_pairs)}\")\n",
        "\n",
        "# 3) Dataset/DataLoader test (avec cache si dispo dans ce notebook)\n",
        "CACHE_DIR = os.path.join(OUTPUT_DIR, \"cache_npz\")\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "test_ds  = MRIDataset3D(DATASET_DIR, test_pairs, cache_dir=CACHE_DIR, use_cache=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=1, shuffle=False,\n",
        "                          num_workers=2, pin_memory=torch.cuda.is_available(),\n",
        "                          persistent_workers=True)\n",
        "\n",
        "# 4) Charger le modèle entraîné\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model  = UNet3D(in_ch=1, out_ch=1).to(device)\n",
        "\n",
        "if not os.path.isfile(CHECKPOINT_PATH):\n",
        "    raise FileNotFoundError(f\"Checkpoint introuvable: {CHECKPOINT_PATH}\")\n",
        "\n",
        "state = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "# Compatibilité stricte : si besoin, mets strict=False\n",
        "model.load_state_dict(state, strict=True)\n",
        "model.eval()\n",
        "print(f\"[INFO] Modèle chargé depuis: {CHECKPOINT_PATH}\")\n",
        "\n",
        "# 5) Lancer l'inférence et sauver dans output_masks/\n",
        "inference_and_save(model, test_loader, device, OUT_MASKS_DIR)\n",
        "print(f\"[OK] Masques sauvegardés sous: {OUT_MASKS_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0GtEGEQRzbY",
        "outputId": "36812914-a7ec-4b63-fe2d-fd50a6fa93f7"
      },
      "id": "l0GtEGEQRzbY",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Nb paires test: 3\n",
            "[INFO] Modèle chargé depuis: /content/drive/MyDrive/Data_test_segmentation/best_model.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 100%|██████████| 3/3 [00:03<00:00,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Masques sauvegardés sous: /content/drive/MyDrive/Data_test_segmentation/output_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}