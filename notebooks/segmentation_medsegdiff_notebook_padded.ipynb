{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c85a41",
   "metadata": {},
   "source": [
    "# Segmentation 3D — Notebook\n",
    "\n",
    "Ce notebook contient un pipeline complet et commenté pour segmenter des tumeurs 3D à partir de volumes `.nii.gz`.\n",
    "\n",
    "**Organisation**:\n",
    "- Entraînement: Timepoint_1 + Timepoint_2\n",
    "- Test: Timepoint_3\n",
    "\n",
    "> Adapté pour usage avec MedSegDiff-V2 (si disponible) ou fallback UNet3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c373d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# Setup - imports et paramètres\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Séquences et nom de masque\n",
    "SEQUENCES = [\"t1c\", \"t2f\", \"t2w\"]\n",
    "MASK_NAME = \"tumorMask\"\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed767d5",
   "metadata": {},
   "source": [
    "## Fonctions utilitaires\n",
    "\n",
    "Chargement/sauvegarde NIfTI et fonctions de visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555acc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "def load_nifti(path):\n",
    "    \"\"\"Charge un fichier NIfTI et retourne (data_float32, affine).\"\"\"\n",
    "    img = nib.load(path)\n",
    "    return img.get_fdata(dtype=np.float32), img.affine\n",
    "\n",
    "def save_nifti(data, affine, out_path):\n",
    "    \"\"\"Sauvegarde data (numpy) au format NIfTI en gardant affine.\"\"\"\n",
    "    img = nib.Nifti1Image(data.astype(np.float32), affine)\n",
    "    nib.save(img, out_path)\n",
    "\n",
    "def find_sequence_file(tp_dir, seq_key):\n",
    "    \"\"\"Retourne le chemin d'un fichier dans tp_dir contenant seq_key dans son nom (ou None).\"\"\"\n",
    "    for f in os.listdir(tp_dir):\n",
    "        if seq_key in f and (f.endswith('.nii') or f.endswith('.nii.gz')):\n",
    "            return os.path.join(tp_dir, f)\n",
    "    return None\n",
    "\n",
    "def show_slices(imgs, masks=None, slice_idx=None, figsize=(12,6)):\n",
    "    \"\"\"Affiche des slices (axial) côte-à-côte pour chaque canal et le masque si fourni.\"\"\"\n",
    "    # imgs : numpy array (C, D, H, W) or (D,H,W)\n",
    "    if imgs.ndim == 4:\n",
    "        C, D, H, W = imgs.shape\n",
    "    elif imgs.ndim == 3:\n",
    "        C = 1\n",
    "        D, H, W = imgs.shape\n",
    "        imgs = imgs[None, ...]\n",
    "    if slice_idx is None:\n",
    "        slice_idx = D // 2\n",
    "    ncols = C + (1 if masks is not None else 0)\n",
    "    fig, axes = plt.subplots(1, ncols, figsize=figsize)\n",
    "    for c in range(C):\n",
    "        ax = axes[c] if ncols>1 else axes\n",
    "        im = imgs[c, slice_idx, :, :]\n",
    "        ax.imshow(im.T, cmap='gray', origin='lower')\n",
    "        ax.set_title(f'Canal {c} - slice {slice_idx}')\n",
    "        ax.axis('off')\n",
    "    if masks is not None:\n",
    "        m = masks if masks.ndim==3 else masks[0]\n",
    "        ax = axes[-1]\n",
    "        ax.imshow(m[slice_idx].T, cmap='gray', origin='lower')\n",
    "        ax.set_title('Masque')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f27c4",
   "metadata": {},
   "source": [
    "## Dataset PyTorch\n",
    "\n",
    "Classe Dataset qui charge les échantillons en respectant la règle : utiliser Timepoint_1 et Timepoint_2 pour l'entraînement et Timepoint_3 pour le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a1ddc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "class MRIDataset3D(Dataset):\n",
    "    \"\"\"Dataset PyTorch pour volumes multi-séquences.\n",
    "    Retourne: (image_tensor, mask_tensor, affine, (patient, timepoint))\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_dir, patients, timepoints, sequences=SEQUENCES):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.patients = patients\n",
    "        self.timepoints = timepoints\n",
    "        self.sequences = sequences\n",
    "        self.samples = []\n",
    "        for patient in patients:\n",
    "            for tp in timepoints:\n",
    "                tp_path = os.path.join(dataset_dir, patient, tp)\n",
    "                if os.path.isdir(tp_path):\n",
    "                    # Vérifier que toutes les séquences et le masque existent\n",
    "                    ok = True\n",
    "                    for s in sequences + [MASK_NAME]:\n",
    "                        if find_sequence_file(tp_path, s) is None:\n",
    "                            ok = False\n",
    "                            break\n",
    "                    if ok:\n",
    "                        self.samples.append((patient, tp))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def pad_to_multiple(vol, multiple=8):\n",
    "        \"\"\"Pad numpy array 3D or 4D (C,D,H,W) so that D,H,W are multiples of 'multiple'.\"\"\"\n",
    "        if vol.ndim == 4:\n",
    "            C, D, H, W = vol.shape\n",
    "            pad_D = (multiple - D % multiple) if D % multiple != 0 else 0\n",
    "            pad_H = (multiple - H % multiple) if H % multiple != 0 else 0\n",
    "            pad_W = (multiple - W % multiple) if W % multiple != 0 else 0\n",
    "            return np.pad(vol, ((0,0),(0,pad_D),(0,pad_H),(0,pad_W)), mode='constant'), (pad_D,pad_H,pad_W)\n",
    "        elif vol.ndim == 3:\n",
    "            D, H, W = vol.shape\n",
    "            pad_D = (multiple - D % multiple) if D % multiple != 0 else 0\n",
    "            pad_H = (multiple - H % multiple) if H % multiple != 0 else 0\n",
    "            pad_W = (multiple - W % multiple) if W % multiple != 0 else 0\n",
    "            return np.pad(vol, ((0,pad_D),(0,pad_H),(0,pad_W)), mode='constant'), (pad_D,pad_H,pad_W)\n",
    "        else:\n",
    "            return vol, (0,0,0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient, tp = self.samples[idx]\n",
    "        tp_path = os.path.join(self.dataset_dir, patient, tp)\n",
    "        channels = []\n",
    "        affine = None\n",
    "        for seq in self.sequences:\n",
    "            p = find_sequence_file(tp_path, seq)\n",
    "            data, a = load_nifti(p)\n",
    "            if affine is None:\n",
    "                affine = a\n",
    "            # z-score normalisation\n",
    "            data = (data - np.mean(data)) / (np.std(data) + 1e-8)\n",
    "            channels.append(data)\n",
    "        mask_p = find_sequence_file(tp_path, MASK_NAME)\n",
    "        mask, _ = load_nifti(mask_p)\n",
    "        mask = (mask > 0).astype(np.float32)\n",
    "        vol = np.stack(channels, axis=0)  # (C, D, H, W)\n",
    "        mask = mask[None, ...]            # (1, D, H, W)\n",
    "        vol, _ = pad_to_multiple(vol, multiple=8)\n",
    "        mask, _ = pad_to_multiple(mask, multiple=8)\n",
    "        return torch.from_numpy(vol.astype(np.float32)), torch.from_numpy(mask.astype(np.float32)), affine, (patient, tp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ca91f0",
   "metadata": {},
   "source": [
    "## Modèle UNet3D (fallback)\n",
    "\n",
    "Architecture UNet3D simple commentée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cefd78eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, 3, padding=1), nn.BatchNorm3d(out_ch), nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_ch, out_ch, 3, padding=1), nn.BatchNorm3d(out_ch), nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=1, base_filters=16):\n",
    "        super().__init__()\n",
    "        f = base_filters\n",
    "        self.enc1 = DoubleConv(in_ch, f)\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        self.enc2 = DoubleConv(f, f*2)\n",
    "        self.enc3 = DoubleConv(f*2, f*4)\n",
    "        self.bottleneck = DoubleConv(f*4, f*8)\n",
    "        self.up3 = nn.ConvTranspose3d(f*8, f*4, 2, stride=2)\n",
    "        self.dec3 = DoubleConv(f*8, f*4)\n",
    "        self.up2 = nn.ConvTranspose3d(f*4, f*2, 2, stride=2)\n",
    "        self.dec2 = DoubleConv(f*4, f*2)\n",
    "        self.up1 = nn.ConvTranspose3d(f*2, f, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(f*2, f)\n",
    "        self.outc = nn.Conv3d(f, out_ch, 1)\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        b = self.bottleneck(self.pool(e3))\n",
    "        d3 = self.up3(b)\n",
    "        d3 = self.dec3(torch.cat([d3, e3], dim=1))\n",
    "        d2 = self.up2(d3)\n",
    "        d2 = self.dec2(torch.cat([d2, e2], dim=1))\n",
    "        d1 = self.up1(d2)\n",
    "        d1 = self.dec1(torch.cat([d1, e1], dim=1))\n",
    "        return self.outc(d1)\n",
    "\n",
    "# Dice loss\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "    def forward(self, logits, target):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        inter = (probs * target).sum(dim=[1,2,3,4])\n",
    "        denom = probs.sum(dim=[1,2,3,4]) + target.sum(dim=[1,2,3,4])\n",
    "        return 1 - ((2*inter + self.eps) / (denom + self.eps)).mean()\n",
    "\n",
    "def dice_coef(logits, target, eps=1e-6):\n",
    "    pred = (torch.sigmoid(logits) > 0.5).float()\n",
    "    inter = (pred * target).sum(dim=[1,2,3,4])\n",
    "    denom = pred.sum(dim=[1,2,3,4]) + target.sum(dim=[1,2,3,4])\n",
    "    return ((2*inter + eps) / (denom + eps)).mean().item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee724d5",
   "metadata": {},
   "source": [
    "## Entraînement\n",
    "\n",
    "Boucles d'entraînement et d'évaluation. Entraîne sur Timepoint_1+Timepoint_2 et évalue sur Timepoint_3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32480571",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "def train_epoch(model, loader, device, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for imgs, masks, _, _ in tqdm(loader, desc='Train'):\n",
    "        imgs = imgs.to(device)\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def eval_epoch(model, loader, device, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_dice = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks, _, _ in tqdm(loader, desc='Eval'):\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, masks)\n",
    "            total_loss += loss.item()\n",
    "            total_dice += dice_coef(logits, masks)\n",
    "    return total_loss / len(loader), total_dice / len(loader)\n",
    "\n",
    "def inference_and_save(model, loader, device, out_dir):\n",
    "    model.eval()\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks, affines, metas in tqdm(loader, desc='Infer'):\n",
    "            imgs = imgs.to(device)\n",
    "            logits = model(imgs)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            for i in range(probs.shape[0]):\n",
    "                pred = (probs[i,0] > 0.5).astype(np.uint8)\n",
    "                patient, tp = metas[i]\n",
    "                out_path = os.path.join(out_dir, patient, tp, 'pred_mask.nii.gz')\n",
    "                os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "                save_nifti(pred, affines[i], out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1937cbd7",
   "metadata": {},
   "source": [
    "## Exemple d'exécution\n",
    "\n",
    "Modifie `DATASET_DIR` et exécute cette cellule pour lancer l'entraînement (GPU recommandé)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5230241c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients retenus: 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/195 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "Caught NameError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_3686504/4224057586.py\", line 63, in __getitem__\n    vol, _ = pad_to_multiple(vol, multiple=8)\nNameError: name 'pad_to_multiple' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m best_dice \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 33\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     val_loss, val_dice \u001b[38;5;241m=\u001b[39m eval_epoch(model, test_loader, device, criterion)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Val Dice: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_dice\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, device, optimizer, criterion)\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imgs, masks, _, _ \u001b[38;5;129;01min\u001b[39;00m tqdm(loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      6\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m     masks \u001b[38;5;241m=\u001b[39m masks\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    740\u001b[0m ):\n",
      "File \u001b[0;32m~/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1516\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1514\u001b[0m worker_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info\u001b[38;5;241m.\u001b[39mpop(idx)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1551\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data, worker_idx)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1551\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages/torch/_utils.py:769\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 769\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mNameError\u001b[0m: Caught NameError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_3686504/4224057586.py\", line 63, in __getitem__\n    vol, _ = pad_to_multiple(vol, multiple=8)\nNameError: name 'pad_to_multiple' is not defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# Paramètres à éditer par l'utilisateur\n",
    "DATASET_DIR = '/home/perfect/Documents/GitHub/projet-AI/data_filter'   # <-- change\n",
    "OUTPUT_DIR = '/home/perfect/Documents/GitHub/projet-AI/data_segmentation'      # <-- change\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 20\n",
    "LR = 1e-4\n",
    "\n",
    "# Lister patients ayant >=3 timepoints\n",
    "patients = []\n",
    "for p in sorted(os.listdir(DATASET_DIR)):\n",
    "    ppath = os.path.join(DATASET_DIR, p)\n",
    "    if not os.path.isdir(ppath): continue\n",
    "    tps = sorted([d for d in os.listdir(ppath) if os.path.isdir(os.path.join(ppath, d))])\n",
    "    if len(tps) >= 3:\n",
    "        patients.append(p)\n",
    "print(f'Patients retenus: {len(patients)}')\n",
    "\n",
    "# Datasets: train = TP1+TP2, test = TP3\n",
    "train_ds = MRIDataset3D(DATASET_DIR, patients, ['Timepoint_1', 'Timepoint_2'])\n",
    "test_ds  = MRIDataset3D(DATASET_DIR, patients, ['Timepoint_3'])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet3D(in_ch=len(SEQUENCES), out_ch=1).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = DiceLoss()\n",
    "\n",
    "best_dice = 0.0\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_loss = train_epoch(model, train_loader, device, optimizer, criterion)\n",
    "    val_loss, val_dice = eval_epoch(model, test_loader, device, criterion)\n",
    "    print(f'Epoch {epoch}/{EPOCHS} - Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}')\n",
    "    # Save best model\n",
    "    if val_dice > best_dice:\n",
    "        best_dice = val_dice\n",
    "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'best_model.pt'))\n",
    "        print('Best model saved.')\n",
    "\n",
    "# Inference and save\n",
    "inference_and_save(model, test_loader, device, os.path.join(OUTPUT_DIR, 'predictions'))\n",
    "print('Done. Predictions saved to', os.path.join(OUTPUT_DIR, 'predictions'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908d33b",
   "metadata": {},
   "source": [
    "## Visualisation des résultats\n",
    "\n",
    "Affiche des slices (axial) des volumes et des masques (vérité terrain et prédiction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc17b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Exemple pour visualiser un patient/timepoint précis (après inférence)\n",
    "def visualize_patient_timepoint(data_root, patient, timepoint, pred_root=None, slice_idx=None):\n",
    "    tp_path = os.path.join(data_root, patient, timepoint)\n",
    "    channels = []\n",
    "    for seq in SEQUENCES:\n",
    "        f = find_sequence_file(tp_path, seq)\n",
    "        d, _ = load_nifti(f)\n",
    "        channels.append(d)\n",
    "    vol = np.stack(channels, axis=0)\n",
    "    mask_f = find_sequence_file(tp_path, MASK_NAME)\n",
    "    mask, _ = load_nifti(mask_f)\n",
    "    pred_mask = None\n",
    "    if pred_root:\n",
    "        pred_p = os.path.join(pred_root, patient, timepoint, 'pred_mask.nii.gz')\n",
    "        if os.path.exists(pred_p):\n",
    "            pred_mask, _ = load_nifti(pred_p)\n",
    "    show_slices(vol, masks=pred_mask if pred_mask is not None else mask, slice_idx=slice_idx)\n",
    "\n",
    "# Usage example (modifier les chemins et ids)\n",
    "# visualize_patient_timepoint(DATASET_DIR, 'PatientID_0162', 'Timepoint_3', pred_root=os.path.join(OUTPUT_DIR,'predictions'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
