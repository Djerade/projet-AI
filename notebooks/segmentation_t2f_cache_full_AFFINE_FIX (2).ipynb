{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "52346d54",
      "metadata": {
        "id": "52346d54"
      },
      "source": [
        "# Segmentation 3D ‚Äî t2f-only (FLAIR) avec cache NPZ\n",
        "Notebook autonome pr√™t √† ex√©cuter : dataset bas√© sur **paires (patient, timepoint)**, **cache** pour acc√©l√©rer, DataLoaders avec **num_workers=2**, et inf√©rence robuste."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cYTjS-aOV-l",
        "outputId": "f2dc8dda-5cdb-4c6a-e7f1-d7b521a4daa4"
      },
      "id": "4cYTjS-aOV-l",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dc9eff8e",
      "metadata": {
        "id": "dc9eff8e"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os, re, json\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "10cb53c2",
      "metadata": {
        "id": "10cb53c2"
      },
      "outputs": [],
      "source": [
        "# Utils: pad & NIfTI loader (signature: (data, affine))\n",
        "def pad_to_multiple(volume, multiple=8, mode='constant', value=0):\n",
        "    \"\"\"Pad 3D/4D array so spatial dims are multiples of `multiple`.\n",
        "    Returns (padded_volume, pad_widths).\"\"\"\n",
        "    if volume.ndim == 3:\n",
        "        shape = volume.shape\n",
        "        pad_widths = []\n",
        "        for dim in shape:\n",
        "            r = dim % multiple\n",
        "            pad_widths.append((0, 0 if r == 0 else multiple - r))\n",
        "        return np.pad(volume, pad_widths, mode=mode, constant_values=value), pad_widths\n",
        "    elif volume.ndim == 4:\n",
        "        shape = volume.shape[1:]\n",
        "        pad_widths = [(0,0)]\n",
        "        for dim in shape:\n",
        "            r = dim % multiple\n",
        "            pad_widths.append((0, 0 if r == 0 else multiple - r))\n",
        "        return np.pad(volume, pad_widths, mode=mode, constant_values=value), pad_widths\n",
        "    else:\n",
        "        raise ValueError(\"Volume must be 3D or 4D\")\n",
        "\n",
        "def load_nifti(path):\n",
        "    img = nib.load(path)\n",
        "    data = img.get_fdata()\n",
        "    return data, img.affine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "34bf1ae4",
      "metadata": {
        "id": "34bf1ae4"
      },
      "outputs": [],
      "source": [
        "# Recherche robuste des fichiers (t2f_processed & tumorMask)\n",
        "from typing import List, Optional\n",
        "\n",
        "SEQ_KEYWORDS  = [\"t2f_processed\", \"t2f\", \"flair\", \"t2_flair\", \"t2fla\"]\n",
        "MASK_KEYWORDS = [\"tumorMask\", \"mask\", \"seg\", \"label\"]\n",
        "\n",
        "def is_nifti(fname: str) -> bool:\n",
        "    low = fname.lower()\n",
        "    return low.endswith(\".nii\") or low.endswith(\".nii.gz\")\n",
        "\n",
        "def find_first_matching_file(folder: str, keywords: List[str]) -> Optional[str]:\n",
        "    keys = [k.lower() for k in keywords]\n",
        "    for fname in sorted(os.listdir(folder)):\n",
        "        if not is_nifti(fname):\n",
        "            continue\n",
        "        low = fname.lower()\n",
        "        if any(k in low for k in keys):\n",
        "            return os.path.join(folder, fname)\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "75b36d0a",
      "metadata": {
        "id": "75b36d0a"
      },
      "outputs": [],
      "source": [
        "# Mod√®le UNet 3D (simple) ‚Äî in_ch=1, out_ch=1\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv3d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.InstanceNorm3d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.InstanceNorm3d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    def __init__(self, in_ch=1, out_ch=1):\n",
        "        super().__init__()\n",
        "        f = 16\n",
        "        self.down1 = DoubleConv(in_ch, f)\n",
        "        self.pool1 = nn.MaxPool3d(2)\n",
        "        self.down2 = DoubleConv(f, f*2)\n",
        "        self.pool2 = nn.MaxPool3d(2)\n",
        "        self.down3 = DoubleConv(f*2, f*4)\n",
        "        self.pool3 = nn.MaxPool3d(2)\n",
        "\n",
        "        self.bottleneck = DoubleConv(f*4, f*8)\n",
        "\n",
        "        self.up3 = nn.ConvTranspose3d(f*8, f*4, 2, stride=2)\n",
        "        self.dec3 = DoubleConv(f*8, f*4)\n",
        "        self.up2 = nn.ConvTranspose3d(f*4, f*2, 2, stride=2)\n",
        "        self.dec2 = DoubleConv(f*4, f*2)\n",
        "        self.up1 = nn.ConvTranspose3d(f*2, f, 2, stride=2)\n",
        "        self.dec1 = DoubleConv(f*2, f)\n",
        "\n",
        "        self.out_conv = nn.Conv3d(f, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        c1 = self.down1(x); p1 = self.pool1(c1)\n",
        "        c2 = self.down2(p1); p2 = self.pool2(c2)\n",
        "        c3 = self.down3(p2); p3 = self.pool3(c3)\n",
        "\n",
        "        b = self.bottleneck(p3)\n",
        "\n",
        "        u3 = self.up3(b); x3 = torch.cat([u3, c3], dim=1); d3 = self.dec3(x3)\n",
        "        u2 = self.up2(d3); x2 = torch.cat([u2, c2], dim=1); d2 = self.dec2(x2)\n",
        "        u1 = self.up1(d2); x1 = torch.cat([u1, c1], dim=1); d1 = self.dec1(x1)\n",
        "        return self.out_conv(d1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8b8585d7",
      "metadata": {
        "id": "8b8585d7"
      },
      "outputs": [],
      "source": [
        "# Dice et loss\n",
        "def dice_coefficient(pred, target, eps=1e-6):\n",
        "    # pred et target en float32 (0..1), taille [B,1,D,H,W]\n",
        "    pred = (pred > 0.5).float()\n",
        "    target = (target > 0.5).float()\n",
        "    inter = (pred * target).sum(dim=(2,3,4))\n",
        "    union = pred.sum(dim=(2,3,4)) + target.sum(dim=(2,3,4))\n",
        "    dice = (2*inter + eps) / (union + eps)\n",
        "    return dice.mean()\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "    def forward(self, logits, targets):\n",
        "        probs = torch.sigmoid(logits)\n",
        "        inter = (probs * targets).sum(dim=(2,3,4))\n",
        "        union = probs.sum(dim=(2,3,4)) + targets.sum(dim=(2,3,4))\n",
        "        dice = (2*inter + self.eps) / (union + self.eps)\n",
        "        return 1 - dice.mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "82dc13c3",
      "metadata": {
        "id": "82dc13c3"
      },
      "outputs": [],
      "source": [
        "# Dataset t2f-only (paires) + cache NPZ\n",
        "class MRIDataset3D(Dataset):\n",
        "    \"\"\"t2f-only. Paires (patient, tp). Cache optionnel (npz).\n",
        "    Retourne: (img[1,D,H,W], mask[1,D,H,W], affine, (patient, tp)).\"\"\"\n",
        "    def __init__(self, dataset_dir, pairs, cache_dir=None, use_cache=True):\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.pairs = list(pairs)\n",
        "        self.cache_dir = cache_dir\n",
        "        self.use_cache = use_cache\n",
        "        if self.cache_dir and self.use_cache:\n",
        "            os.makedirs(self.cache_dir, exist_ok=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        patient, tp = self.pairs[idx]\n",
        "        tp_path = os.path.join(self.dataset_dir, patient, tp)\n",
        "\n",
        "        cache_path = None\n",
        "        if self.cache_dir and self.use_cache:\n",
        "            cache_path = os.path.join(self.cache_dir, f\"{patient}__{tp}.npz\")\n",
        "\n",
        "        if cache_path is not None and os.path.isfile(cache_path):\n",
        "            z = np.load(cache_path)\n",
        "            vol    = z[\"vol\"]      # (1,D,H,W) float32\n",
        "            mask   = z[\"mask\"]     # (1,D,H,W) float32 (0/1)\n",
        "            affine = z[\"affine\"]\n",
        "        else:\n",
        "            # t2f\n",
        "            t2f_path = find_first_matching_file(tp_path, SEQ_KEYWORDS)\n",
        "            if t2f_path is None:\n",
        "                raise FileNotFoundError(f\"[t2f introuvable] {patient}/{tp}\")\n",
        "            vol, affine = load_nifti(t2f_path)\n",
        "\n",
        "            # mask\n",
        "            mask_path = find_first_matching_file(tp_path, MASK_KEYWORDS)\n",
        "            if mask_path is None:\n",
        "                raise FileNotFoundError(f\"[mask introuvable] {patient}/{tp}\")\n",
        "            mask, _ = load_nifti(mask_path)\n",
        "\n",
        "            # pr√©traitements\n",
        "            vol = vol.astype(np.float32, copy=False)\n",
        "            vol = (vol - vol.mean()) / (vol.std() + 1e-8)\n",
        "            vol = vol[None, ...]  # (1,D,H,W)\n",
        "            mask = (mask > 0).astype(np.float32)[None, ...]  # (1,D,H,W)\n",
        "\n",
        "            vol, _  = pad_to_multiple(vol, multiple=8)\n",
        "            mask, _ = pad_to_multiple(mask, multiple=8)\n",
        "\n",
        "            if cache_path is not None:\n",
        "                np.savez_compressed(cache_path, vol=vol, mask=mask, affine=affine)\n",
        "\n",
        "        # üîí assure l'affine en np.float64 (4x4) avant retour\n",
        "        affine = np.asarray(affine, dtype=np.float64)\n",
        "\n",
        "        return (torch.from_numpy(vol), torch.from_numpy(mask), affine, (patient, tp))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4e63078a",
      "metadata": {
        "id": "4e63078a"
      },
      "outputs": [],
      "source": [
        "# Entra√Ænement / √©valuation\n",
        "def train_epoch(model, loader, device, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for imgs, masks, _, _ in tqdm(loader, desc=\"Train\"):\n",
        "        imgs  = imgs.to(device, non_blocking=True)\n",
        "        masks = masks.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(imgs)\n",
        "        loss = criterion(logits, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "    return total_loss / max(1, len(loader.dataset))\n",
        "\n",
        "def eval_epoch(model, loader, device, criterion):\n",
        "    model.eval()\n",
        "    total_loss, total_dice, n = 0.0, 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, masks, _, _ in tqdm(loader, desc=\"Val\"):\n",
        "            imgs  = imgs.to(device, non_blocking=True)\n",
        "            masks = masks.to(device, non_blocking=True)\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, masks)\n",
        "            probs = torch.sigmoid(logits)\n",
        "            dice  = dice_coefficient(probs, masks)\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            total_dice += dice.item() * imgs.size(0)\n",
        "            n += imgs.size(0)\n",
        "    return total_loss / max(1,n), total_dice / max(1,n)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "be9548d9",
      "metadata": {
        "id": "be9548d9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Inf√©rence robuste (g√®re diff√©rents formats de metas) + affine (4x4)\n",
        "def inference_and_save(model, loader, device, out_dir):\n",
        "    import numpy as np\n",
        "    import torch, os\n",
        "    import nibabel as nib\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    model.eval()\n",
        "\n",
        "    def get_meta_pair(metas, i):\n",
        "        # ( [patients], [tps] )\n",
        "        if isinstance(metas, (list, tuple)) and len(metas) == 2 and \\\n",
        "           all(isinstance(x, (list, tuple)) for x in metas):\n",
        "            return metas[0][i], metas[1][i]\n",
        "        # [ (patient, tp), ... ]\n",
        "        if isinstance(metas, (list, tuple)) and len(metas) > 0 and \\\n",
        "           isinstance(metas[0], (list, tuple)) and len(metas[0]) == 2:\n",
        "            return metas[i][0], metas[i][1]\n",
        "        # (patient, tp) si B=1\n",
        "        if isinstance(metas, (list, tuple)) and len(metas) == 2 and \\\n",
        "           not any(isinstance(x, (list, tuple)) for x in metas):\n",
        "            return metas[0], metas[1]\n",
        "        # \".../PatientID/Timepoint\" ou \"...\\\\PatientID\\\\Timepoint\"\n",
        "        if isinstance(metas, (list, tuple)) and len(metas) > 0 and isinstance(metas[i], str):\n",
        "            s = metas[i].replace('\\\\', '/').split('/')\n",
        "            if len(s) >= 2:\n",
        "                return s[-2], s[-1]\n",
        "        raise ValueError(f\"Format metas non support√©: type={type(metas)} exemple={metas}\")\n",
        "\n",
        "    def get_affine_i(affines, i):\n",
        "        # torch.Tensor\n",
        "        if isinstance(affines, torch.Tensor):\n",
        "            a = affines[i] if affines.ndim == 3 else affines\n",
        "            a = a.detach().cpu().numpy()\n",
        "        # numpy array\n",
        "        elif isinstance(affines, np.ndarray):\n",
        "            a = affines[i] if affines.ndim == 3 else affines\n",
        "        # list/tuple\n",
        "        elif isinstance(affines, (list, tuple)):\n",
        "            if len(affines) == 0:\n",
        "                raise ValueError(\"Liste d'affines vide\")\n",
        "            a = affines[i] if len(affines) > 1 else affines[0]\n",
        "            a = np.asarray(a)\n",
        "        else:\n",
        "            a = np.asarray(affines)\n",
        "\n",
        "        a = np.asarray(a, dtype=np.float64)\n",
        "        if a.shape != (4, 4):\n",
        "            raise ValueError(f\"Affine devrait √™tre (4,4), re√ßu {a.shape} (type {type(a)})\")\n",
        "        return a\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc='Inference'):\n",
        "            imgs, _, affines, metas = batch\n",
        "            imgs = imgs.to(device, non_blocking=True)\n",
        "            logits = model(imgs)               # [B,1,D,H,W]\n",
        "            probs  = torch.sigmoid(logits).cpu().numpy()\n",
        "\n",
        "            B = probs.shape[0]\n",
        "            for i in range(B):\n",
        "                pred = (probs[i, 0] > 0.5).astype(np.uint8)\n",
        "                patient, tp = get_meta_pair(metas, i)\n",
        "                affine = get_affine_i(affines, i)\n",
        "\n",
        "                out_path = os.path.join(out_dir, patient, tp, 'pred_mask.nii.gz')\n",
        "                os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "                nib.save(nib.Nifti1Image(pred.astype(np.uint8), affine), out_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dc032296",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc032296",
        "outputId": "09dc7d04-2876-44fa-8351-e580f29e1c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patients retenus (>=2 TP): 3\n",
            "Taille attendue ~ train=6 | test=3\n"
          ]
        }
      ],
      "source": [
        "# Param√®tres & DataLoaders (Windows-friendly paths)\n",
        "# ‚ö†Ô∏è Adapte ces chemins √† ta machine. Utilise des slashes '/' ou des raw strings r'...'\n",
        "DATASET_DIR = r'/content/drive/MyDrive/Data_test'\n",
        "OUTPUT_DIR  = r'/content/drive/MyDrive/Data_test_segmentation'\n",
        "BATCH_SIZE  = 1\n",
        "EPOCHS      = 20\n",
        "LR          = 1e-4\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, 'predictions'), exist_ok=True)\n",
        "\n",
        "# Cache\n",
        "CACHE_DIR = os.path.join(OUTPUT_DIR, 'cache_npz')\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "# Lister patients et timepoints\n",
        "patients_timepoints = {}\n",
        "for p in sorted(os.listdir(DATASET_DIR)):\n",
        "    ppath = os.path.join(DATASET_DIR, p)\n",
        "    if not os.path.isdir(ppath):\n",
        "        continue\n",
        "    tps = sorted([d for d in os.listdir(ppath) if os.path.isdir(os.path.join(ppath, d))])\n",
        "    if len(tps) >= 3:\n",
        "        patients_timepoints[p] = tps[:3]   # 2 train + 1 test\n",
        "    elif len(tps) == 2:\n",
        "        patients_timepoints[p] = tps       # 1 train + 1 test\n",
        "    # sinon (1 TP): ignore\n",
        "\n",
        "print(f\"Patients retenus (>=2 TP): {len(patients_timepoints)}\")\n",
        "\n",
        "# Paires (patient,tp)\n",
        "train_pairs, test_pairs = [], []\n",
        "for p, tps in patients_timepoints.items():\n",
        "    if len(tps) >= 3:\n",
        "        train_pairs.extend([(p, tps[0]), (p, tps[1])])\n",
        "        test_pairs.append((p, tps[2]))\n",
        "    elif len(tps) == 2:\n",
        "        train_pairs.append((p, tps[0]))\n",
        "        test_pairs.append((p, tps[1]))\n",
        "\n",
        "print(f\"Taille attendue ~ train={len(train_pairs)} | test={len(test_pairs)}\")\n",
        "\n",
        "# Datasets & loaders\n",
        "train_ds = MRIDataset3D(DATASET_DIR, train_pairs, cache_dir=CACHE_DIR, use_cache=True)\n",
        "test_ds  = MRIDataset3D(DATASET_DIR, test_pairs,  cache_dir=CACHE_DIR, use_cache=True)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=2, pin_memory=torch.cuda.is_available(),\n",
        "                          persistent_workers=True)\n",
        "\n",
        "test_loader  = DataLoader(test_ds,  batch_size=1, shuffle=False,\n",
        "                          num_workers=2, pin_memory=torch.cuda.is_available(),\n",
        "                          persistent_workers=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet3D(in_ch=1, out_ch=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = DiceLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "59ff59ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59ff59ea",
        "outputId": "a21c00de-44b9-4716-969d-54864884a001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:19<00:00,  3.27s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n",
            "Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:15<00:00,  2.58s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n",
            "Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:15<00:00,  2.60s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:15<00:00,  2.62s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n",
            "Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:15<00:00,  2.65s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:16<00:00,  2.72s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:16<00:00,  2.70s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:16<00:00,  2.73s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n",
            "Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:16<00:00,  2.79s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:17<00:00,  2.88s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:17<00:00,  2.89s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:16<00:00,  2.82s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n",
            "Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:16<00:00,  2.80s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:16<00:00,  2.81s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:17<00:00,  2.85s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:17<00:00,  2.85s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:17<00:00,  2.85s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n",
            "Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:17<00:00,  2.83s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:17<00:00,  2.87s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:16<00:00,  2.83s/it]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20 - Train Loss: 1.0000 | Val Loss: 1.0000 | Val Dice: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Entra√Ænement + sauvegarde meilleur mod√®le\n",
        "best_dice = 0.0\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train_loss = train_epoch(model, train_loader, device, optimizer, criterion)\n",
        "    val_loss, val_dice = eval_epoch(model, test_loader, device, criterion)\n",
        "    print(f'Epoch {epoch}/{EPOCHS} - Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}')\n",
        "    if val_dice > best_dice:\n",
        "        best_dice = val_dice\n",
        "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'best_model.pt'))\n",
        "        print('Best model saved.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6be7a540",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6be7a540",
        "outputId": "dc8e1168-f0f1-4285-9eaf-601937b36bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Predictions saved to /content/drive/MyDrive/Data_test_segmentation/predictions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Inf√©rence\n",
        "inference_and_save(model, test_loader, device, os.path.join(OUTPUT_DIR, 'predictions'))\n",
        "print('Done. Predictions saved to', os.path.join(OUTPUT_DIR, 'predictions'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Inference-only : charger le mod√®le entra√Æn√© et sauver dans output_masks/ ======\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# 1) Chemins (r√©utilise OUTPUT_DIR/DATASET_DIR d√©j√† d√©finis plus haut)\n",
        "CHECKPOINT_PATH = os.path.join(OUTPUT_DIR, \"/content/drive/MyDrive/Data_test_segmentation/best_model.pt\")\n",
        "OUT_MASKS_DIR   = os.path.join(OUTPUT_DIR, \"output_masks\")\n",
        "os.makedirs(OUT_MASKS_DIR, exist_ok=True)\n",
        "\n",
        "# 2) Recr√©er le dataset TEST (patients avec >=2 TP : test = TP3 si dispo, sinon TP2)\n",
        "patients_timepoints = {}\n",
        "for p in sorted(os.listdir(DATASET_DIR)):\n",
        "    ppath = os.path.join(DATASET_DIR, p)\n",
        "    if not os.path.isdir(ppath):\n",
        "        continue\n",
        "    tps = sorted([d for d in os.listdir(ppath) if os.path.isdir(os.path.join(ppath, d))])\n",
        "    if len(tps) >= 3:\n",
        "        patients_timepoints[p] = tps[:3]   # (TP1, TP2, TP3)\n",
        "    elif len(tps) == 2:\n",
        "        patients_timepoints[p] = tps       # (TP1, TP2)\n",
        "    # sinon: ignor√©\n",
        "\n",
        "# paires test : 3e si dispo, sinon 2e\n",
        "test_pairs = []\n",
        "for p, tps in patients_timepoints.items():\n",
        "    if len(tps) >= 3:\n",
        "        test_pairs.append((p, tps[2]))\n",
        "    elif len(tps) == 2:\n",
        "        test_pairs.append((p, tps[1]))\n",
        "\n",
        "print(f\"[INFO] Nb paires test: {len(test_pairs)}\")\n",
        "\n",
        "# 3) Dataset/DataLoader test (avec cache si dispo dans ce notebook)\n",
        "CACHE_DIR = os.path.join(OUTPUT_DIR, \"cache_npz\")\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "test_ds  = MRIDataset3D(DATASET_DIR, test_pairs, cache_dir=CACHE_DIR, use_cache=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=1, shuffle=False,\n",
        "                          num_workers=2, pin_memory=torch.cuda.is_available(),\n",
        "                          persistent_workers=True)\n",
        "\n",
        "# 4) Charger le mod√®le entra√Æn√©\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model  = UNet3D(in_ch=1, out_ch=1).to(device)\n",
        "\n",
        "if not os.path.isfile(CHECKPOINT_PATH):\n",
        "    raise FileNotFoundError(f\"Checkpoint introuvable: {CHECKPOINT_PATH}\")\n",
        "\n",
        "state = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "# Compatibilit√© stricte : si besoin, mets strict=False\n",
        "model.load_state_dict(state, strict=True)\n",
        "model.eval()\n",
        "print(f\"[INFO] Mod√®le charg√© depuis: {CHECKPOINT_PATH}\")\n",
        "\n",
        "# 5) Lancer l'inf√©rence et sauver dans output_masks/\n",
        "inference_and_save(model, test_loader, device, OUT_MASKS_DIR)\n",
        "print(f\"[OK] Masques sauvegard√©s sous: {OUT_MASKS_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0GtEGEQRzbY",
        "outputId": "36812914-a7ec-4b63-fe2d-fd50a6fa93f7"
      },
      "id": "l0GtEGEQRzbY",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Nb paires test: 3\n",
            "[INFO] Mod√®le charg√© depuis: /content/drive/MyDrive/Data_test_segmentation/best_model.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Masques sauvegard√©s sous: /content/drive/MyDrive/Data_test_segmentation/output_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}