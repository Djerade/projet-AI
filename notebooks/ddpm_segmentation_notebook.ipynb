{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3df553",
   "metadata": {},
   "source": [
    "\n",
    "# DDPM-based Segmentation (2D slice) — Notebook\n",
    "\n",
    "**But**: segmentation de tumeur avec un modèle de diffusion conditionné sur images multi-modalité (T1c, T2f, T2w).\n",
    "\n",
    "**Ce notebook fournit** :\n",
    "- un loader 2D (slices) depuis `RESULTS_DIR` (prétraité)\n",
    "- un UNet simple conditionné par l'image + bruit de masque\n",
    "- utilitaires diffusion (q_sample) et une fonction d'échantillonnage simple\n",
    "- boucle d'entraînement **squelette** (adapter batch_size / epochs)\n",
    "- fonctions de visualisation (overlay mask)\n",
    "\n",
    "> **Important** : ce notebook est un point de départ pédagogique. Pour usage réel, adapte la gestion GPU, la formule exacte de reverse DDPM, les normalisations et augmente le dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d16ba23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nibabel in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (5.3.2)\n",
      "Collecting torch\n",
      "  Using cached torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl (888.0 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.23.0-cp310-cp310-manylinux_2_28_x86_64.whl (8.6 MB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: matplotlib in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (3.10.5)\n",
      "Requirement already satisfied: numpy in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: packaging>=20 in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (from nibabel) (25.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (from nibabel) (4.14.1)\n",
      "Requirement already satisfied: importlib-resources>=5.12 in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (from nibabel) (6.5.2)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.8.90\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m881.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.5.8.93\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "Requirement already satisfied: networkx in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy>=1.13.3\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.27.3\n",
      "  Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.4.0\n",
      "  Downloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.7.3.90\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.6/199.6 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.10.2.21\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m861.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:07\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/nvidia-curand-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting nvidia-curand-cu12==10.3.9.90\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.8.90\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=40.8.0 in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (from triton==3.4.0->torch) (59.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/perfect/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, triton, tqdm, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.7.0 mpmath-1.3.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.8.0 torchvision-0.23.0 tqdm-4.67.1 triton-3.4.0\n"
     ]
    }
   ],
   "source": [
    "# Installer dépendances si nécessaire (décommente si besoin)\n",
    "!pip install nibabel torch torchvision tqdm matplotlib numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3744fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/chemin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m RESULTS_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/perfect/Documents/GitHub/projet-AI/data_filter\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# dossier contenant PatientID/Timepoint/*.nii.gz\u001b[39;00m\n\u001b[1;32m      3\u001b[0m OUTPUT_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chemin/vers/output_ddpm\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m SEQUENCES \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt1c\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt2f\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt2w\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m MASK_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtumorMask\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/chemin'"
     ]
    }
   ],
   "source": [
    "# Paramètres principaux - MODIFIE LES CHEMINS AVANT D'EXÉCUTER\n",
    "RESULTS_DIR = \"/home/perfect/Documents/GitHub/projet-AI/data_filter\"  # dossier contenant PatientID/Timepoint/*.nii.gz\n",
    "OUTPUT_DIR = \"/home/perfect/Documents/GitHub/projet-AI/data_segmentation\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "SEQUENCES = ['t1c', 't2f', 't2w']\n",
    "MASK_NAME = 'tumorMask'\n",
    "\n",
    "# Entraînement - valeurs par défaut pour test rapide\n",
    "DEVICE = 'cuda' if __import__('torch').cuda.is_available() else 'cpu'\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 4\n",
    "LR = 2e-4\n",
    "TIMESTEPS = 200  # réduit pour tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa4a49d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DEVICE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPyTorch device:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mDEVICE\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DEVICE' is not defined"
     ]
    }
   ],
   "source": [
    "import os, math, random\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print('PyTorch device:', DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ae77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Diffusion utilities (basic) ---\n",
    "def linear_beta_schedule(timesteps, beta_start=1e-4, beta_end=2e-2):\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "class Diffusion:\n",
    "    def __init__(self, timesteps=1000, device='cpu'):\n",
    "        self.timesteps = timesteps\n",
    "        self.device = device\n",
    "        betas = linear_beta_schedule(timesteps).to(device)\n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        alphas_cumprod_prev = torch.cat([torch.tensor([1.], device=device), alphas_cumprod[:-1]])\n",
    "        self.betas = betas\n",
    "        self.alphas = alphas\n",
    "        self.alphas_cumprod = alphas_cumprod\n",
    "        self.alphas_cumprod_prev = alphas_cumprod_prev\n",
    "\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - alphas_cumprod)\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        # x_start: (B,1,H,W)\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_start)\n",
    "        sqrt_acp = self.sqrt_alphas_cumprod[t].view(-1,1,1,1)\n",
    "        sqrt_omacp = self.sqrt_one_minus_alphas_cumprod[t].view(-1,1,1,1)\n",
    "        return sqrt_acp * x_start + sqrt_omacp * noise, noise\n",
    "\n",
    "# small helper to get scalar tensors\n",
    "def t_to_device(t, device):\n",
    "    return t.to(device).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4311669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlicesDataset(Dataset):\n",
    "    def __init__(self, results_dir, sequences=['t1c','t2f','t2w'], mask_name='tumorMask', transform=None):\n",
    "        self.results_dir = Path(results_dir)\n",
    "        self.sequences = sequences\n",
    "        self.mask_name = mask_name\n",
    "        self.transform = transform\n",
    "        self.index = []  # list of tuples (tp_path, z)\n",
    "\n",
    "        # build index\n",
    "        for patient in sorted(os.listdir(results_dir)):\n",
    "            pth = Path(results_dir) / patient\n",
    "            if not pth.is_dir(): continue\n",
    "            for tp in sorted(os.listdir(pth)):\n",
    "                tp_path = pth / tp\n",
    "                if not tp_path.is_dir(): continue\n",
    "                # check files exist\n",
    "                seq_files = {s: list(tp_path.glob(f'*{s}*.nii*')) for s in sequences}\n",
    "                mask_files = list(tp_path.glob(f'*{mask_name}*.nii*'))\n",
    "                if any(len(seq_files[s])==0 for s in sequences) or len(mask_files)==0:\n",
    "                    continue\n",
    "                # load one modality to know shape\n",
    "                sample_img = nib.load(str(seq_files[sequences[0]][0])).get_fdata()\n",
    "                H,W,D = sample_img.shape\n",
    "                for z in range(D):\n",
    "                    self.index.append((str(tp_path), int(z)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tp_path, z = self.index[idx]\n",
    "        tp_path = Path(tp_path)\n",
    "        seq_imgs = {}\n",
    "        for s in self.sequences:\n",
    "            f = list(tp_path.glob(f'*{s}*.nii*'))[0]\n",
    "            arr = nib.load(str(f)).get_fdata().astype(np.float32)\n",
    "            # per-slice normalization (zero mean, unit std)\n",
    "            arr = (arr - arr.mean()) / (arr.std() + 1e-8)\n",
    "            seq_imgs[s] = arr\n",
    "        mask_f = list(tp_path.glob(f'*{self.mask_name}*.nii*'))[0]\n",
    "        mask = nib.load(str(mask_f)).get_fdata().astype(np.float32)\n",
    "        in_slice = np.stack([seq_imgs[s][:,:,z] for s in self.sequences], axis=0)  # (C,H,W)\n",
    "        mask_slice = (mask[:,:,z] > 0).astype(np.float32)[None,...]  # (1,H,W)\n",
    "        return torch.from_numpy(in_slice).float(), torch.from_numpy(mask_slice).float()\n",
    "\n",
    "# quick sanity\n",
    "# ds = SlicesDataset(RESULTS_DIR)\n",
    "# print('dataset size', len(ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e67d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "class SimpleUNetCond(nn.Module):\n",
    "    def __init__(self, in_ch=4, base=32):\n",
    "        super().__init__()\n",
    "        self.inc = DoubleConv(in_ch, base)\n",
    "        self.down1 = DoubleConv(base, base*2)\n",
    "        self.down2 = DoubleConv(base*2, base*4)\n",
    "        self.up1 = DoubleConv(base*4, base*2)\n",
    "        self.up2 = DoubleConv(base*2, base)\n",
    "        self.outc = nn.Conv2d(base, 1, 1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(self.pool(x1))\n",
    "        x3 = self.down2(self.pool(x2))\n",
    "        u1 = F.interpolate(x3, scale_factor=2, mode='nearest')\n",
    "        u1 = self.up1(u1)\n",
    "        u2 = F.interpolate(u1, scale_factor=2, mode='nearest')\n",
    "        u2 = self.up2(u2)\n",
    "        out = self.outc(u2 + x1)\n",
    "        return out\n",
    "\n",
    "# model = SimpleUNetCond(in_ch=4).to(DEVICE)\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(results_dir, epochs=EPOCHS, batch_size=BATCH_SIZE, lr=LR, timesteps=TIMESTEPS, device=DEVICE):\n",
    "    device = torch.device(device)\n",
    "    ds = SlicesDataset(results_dir, sequences=SEQUENCES, mask_name=MASK_NAME)\n",
    "    dl = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    model = SimpleUNetCond(in_ch=4).to(device)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    diff = Diffusion(timesteps=timesteps, device=device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(dl, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        running_loss = 0.0\n",
    "        for imgs, masks in pbar:\n",
    "            imgs = imgs.to(device)       # (B,3,H,W)\n",
    "            masks = masks.to(device)     # (B,1,H,W)\n",
    "            b = imgs.shape[0]\n",
    "            t = torch.randint(0, diff.timesteps, (b,), device=device)\n",
    "            x_t, noise = diff.q_sample(masks, t)\n",
    "            # prepare model input = concat(condition images + x_t noisy mask)\n",
    "            inp = torch.cat([imgs, x_t], dim=1)  # (B,4,H,W)\n",
    "            pred = model(inp)  # predict noise or x0; here we predict noise\n",
    "            loss = F.mse_loss(pred, noise)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix(loss=running_loss / (pbar.n+1e-8))\n",
    "        # save checkpoint\n",
    "        ckpt_path = os.path.join(OUTPUT_DIR, f'model_epoch_{epoch+1}.pth')\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "        print('Saved', ckpt_path)\n",
    "\n",
    "    return model, diff\n",
    "\n",
    "# WARNING: launching training may be long. Uncomment to run:\n",
    "# model, diff = train(RESULTS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506dcdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(model, diff, cond_imgs, steps=None, device=DEVICE):\n",
    "    device = torch.device(device)\n",
    "    model.eval()\n",
    "    b, c, h, w = cond_imgs.shape\n",
    "    steps = steps or diff.timesteps\n",
    "    x = torch.randn((b,1,h,w), device=device)\n",
    "    for i in reversed(range(diff.timesteps)):\n",
    "        t = torch.full((b,), i, device=device, dtype=torch.long)\n",
    "        inp = torch.cat([cond_imgs, x], dim=1)  # (B,4,H,W)\n",
    "        pred_noise = model(inp)\n",
    "        beta = diff.betas[i]\n",
    "        alpha = diff.alphas[i]\n",
    "        alpha_cum = diff.alphas_cumprod[i]\n",
    "        # simplified posterior mean update (not exact ddpm)\n",
    "        x = (1.0 / torch.sqrt(alpha)) * (x - (beta / torch.sqrt(1 - alpha_cum)) * pred_noise)\n",
    "        if i > 0:\n",
    "            x = x + torch.sqrt(beta) * torch.randn_like(x)\n",
    "    # x is continuous mask; threshold\n",
    "    return (x.clamp(-1,1) > 0).float()\n",
    "\n",
    "def show_overlay(cond_img_np, mask_np, title=''):\n",
    "    # cond_img_np: (3,H,W) numpy, mask_np: (1,H,W)\n",
    "    t1c = cond_img_np[0]\n",
    "    mask = mask_np[0]\n",
    "    mid = mask.shape[1]//2\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(t1c, cmap='gray')\n",
    "    plt.imshow(np.ma.masked_where(mask==0, mask), cmap='autumn', alpha=0.5)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36500d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Exemple d'utilisation ===\n",
    "# 1) Lancer l'entraînement (décommente si tu veux exécuter)\n",
    "# model, diff = train(RESULTS_DIR, epochs=2)\n",
    "\n",
    "# 2) Après entraînement charger un checkpoint et échantillonner sur un batch de validation\n",
    "# device = torch.device(DEVICE)\n",
    "# model = SimpleUNetCond(in_ch=4).to(device)\n",
    "# model.load_state_dict(torch.load('/chemin/vers/output_ddpm/model_epoch_2.pth', map_location=device))\n",
    "# ds = SlicesDataset(RESULTS_DIR)\n",
    "# dl = DataLoader(ds, batch_size=2, shuffle=True)\n",
    "# imgs, masks = next(iter(dl))\n",
    "# imgs = imgs.to(device)\n",
    "# pred_mask = sample(model, diff, imgs)\n",
    "# show_overlay(imgs[0].cpu().numpy(), pred_mask[0].cpu().numpy(), title='Prediction overlay')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372b691",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Next steps / améliorations recommandées\n",
    "- Remplacer l'update d'échantillonnage par la formule complète p(x_{t-1}|x_t) (voir DDPM paper).\n",
    "- Ajouter time embedding injectée dans chaque bloc UNet.\n",
    "- Utiliser augmentation (torchio / MONAI), early stopping, validation set.\n",
    "- Pour 3D : entraînement patch-based 3D ou 2.5D avec stacks de slices.\n",
    "- Post-traitement : seuillage, morpho, largest connected component.\n",
    "\n",
    "Good luck — adapte les hyperparamètres et bon entraînement !\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
