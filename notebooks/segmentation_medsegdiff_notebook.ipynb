{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c85a41",
   "metadata": {},
   "source": [
    "# Segmentation 3D — Notebook\n",
    "\n",
    "Ce notebook contient un pipeline complet et commenté pour segmenter des tumeurs 3D à partir de volumes `.nii.gz`.\n",
    "\n",
    "**Organisation**:\n",
    "- Entraînement: Timepoint_1 + Timepoint_2\n",
    "- Test: Timepoint_3\n",
    "\n",
    "> Adapté pour usage avec MedSegDiff-V2 (si disponible) ou fallback UNet3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c373d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# Setup - imports et paramètres\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Séquences et nom de masque\n",
    "SEQUENCES = [\"t1c\", \"t2f\", \"t2w\"]\n",
    "MASK_NAME = \"tumorMask\"\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed767d5",
   "metadata": {},
   "source": [
    "## Fonctions utilitaires\n",
    "\n",
    "Chargement/sauvegarde NIfTI et fonctions de visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "555acc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "def load_nifti(path):\n",
    "    \"\"\"Charge un fichier NIfTI et retourne (data_float32, affine).\"\"\"\n",
    "    img = nib.load(path)\n",
    "    return img.get_fdata(dtype=np.float32), img.affine\n",
    "\n",
    "def save_nifti(data, affine, out_path):\n",
    "    \"\"\"Sauvegarde data (numpy) au format NIfTI en gardant affine.\"\"\"\n",
    "    img = nib.Nifti1Image(data.astype(np.float32), affine)\n",
    "    nib.save(img, out_path)\n",
    "\n",
    "def find_sequence_file(tp_dir, seq_key):\n",
    "    \"\"\"Retourne le chemin d'un fichier dans tp_dir contenant seq_key dans son nom (ou None).\"\"\"\n",
    "    for f in os.listdir(tp_dir):\n",
    "        if seq_key in f and (f.endswith('.nii') or f.endswith('.nii.gz')):\n",
    "            return os.path.join(tp_dir, f)\n",
    "    return None\n",
    "\n",
    "def show_slices(imgs, masks=None, slice_idx=None, figsize=(12,6)):\n",
    "    \"\"\"Affiche des slices (axial) côte-à-côte pour chaque canal et le masque si fourni.\"\"\"\n",
    "    # imgs : numpy array (C, D, H, W) or (D,H,W)\n",
    "    if imgs.ndim == 4:\n",
    "        C, D, H, W = imgs.shape\n",
    "    elif imgs.ndim == 3:\n",
    "        C = 1\n",
    "        D, H, W = imgs.shape\n",
    "        imgs = imgs[None, ...]\n",
    "    if slice_idx is None:\n",
    "        slice_idx = D // 2\n",
    "    ncols = C + (1 if masks is not None else 0)\n",
    "    fig, axes = plt.subplots(1, ncols, figsize=figsize)\n",
    "    for c in range(C):\n",
    "        ax = axes[c] if ncols>1 else axes\n",
    "        im = imgs[c, slice_idx, :, :]\n",
    "        ax.imshow(im.T, cmap='gray', origin='lower')\n",
    "        ax.set_title(f'Canal {c} - slice {slice_idx}')\n",
    "        ax.axis('off')\n",
    "    if masks is not None:\n",
    "        m = masks if masks.ndim==3 else masks[0]\n",
    "        ax = axes[-1]\n",
    "        ax.imshow(m[slice_idx].T, cmap='gray', origin='lower')\n",
    "        ax.set_title('Masque')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f27c4",
   "metadata": {},
   "source": [
    "## Dataset PyTorch\n",
    "\n",
    "Classe Dataset qui charge les échantillons en respectant la règle : utiliser Timepoint_1 et Timepoint_2 pour l'entraînement et Timepoint_3 pour le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f938e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "class MRIDataset3D(Dataset):\n",
    "    \"\"\"Dataset PyTorch pour volumes multi-séquences.\n",
    "    Retourne: (image_tensor, mask_tensor, affine, (patient, timepoint))\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_dir, patients, timepoints, sequences=SEQUENCES):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.patients = patients\n",
    "        self.timepoints = timepoints\n",
    "        self.sequences = sequences\n",
    "        self.samples = []\n",
    "        for patient in patients:\n",
    "            for tp in timepoints:\n",
    "                tp_path = os.path.join(dataset_dir, patient, tp)\n",
    "                if os.path.isdir(tp_path):\n",
    "                    # Vérifier que toutes les séquences et le masque existent\n",
    "                    ok = True\n",
    "                    for s in sequences + [MASK_NAME]:\n",
    "                        if find_sequence_file(tp_path, s) is None:\n",
    "                            ok = False\n",
    "                            break\n",
    "                    if ok:\n",
    "                        self.samples.append((patient, tp))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient, tp = self.samples[idx]\n",
    "        tp_path = os.path.join(self.dataset_dir, patient, tp)\n",
    "        channels = []\n",
    "        affine = None\n",
    "        for seq in self.sequences:\n",
    "            p = find_sequence_file(tp_path, seq)\n",
    "            data, a = load_nifti(p)\n",
    "            if affine is None:\n",
    "                affine = a\n",
    "            # z-score normalisation\n",
    "            data = (data - np.mean(data)) / (np.std(data) + 1e-8)\n",
    "            channels.append(data)\n",
    "        mask_p = find_sequence_file(tp_path, MASK_NAME)\n",
    "        mask, _ = load_nifti(mask_p)\n",
    "        mask = (mask > 0).astype(np.float32)\n",
    "        vol = np.stack(channels, axis=0)  # (C, D, H, W)\n",
    "        mask = mask[None, ...]            # (1, D, H, W)\n",
    "        return torch.from_numpy(vol.astype(np.float32)), torch.from_numpy(mask.astype(np.float32)), affine, (patient, tp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ca91f0",
   "metadata": {},
   "source": [
    "## Modèle UNet3D (fallback)\n",
    "\n",
    "Architecture UNet3D simple commentée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cefd78eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, 3, padding=1), nn.BatchNorm3d(out_ch), nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_ch, out_ch, 3, padding=1), nn.BatchNorm3d(out_ch), nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=1, base_filters=16):\n",
    "        super().__init__()\n",
    "        f = base_filters\n",
    "        self.enc1 = DoubleConv(in_ch, f)\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        self.enc2 = DoubleConv(f, f*2)\n",
    "        self.enc3 = DoubleConv(f*2, f*4)\n",
    "        self.bottleneck = DoubleConv(f*4, f*8)\n",
    "        self.up3 = nn.ConvTranspose3d(f*8, f*4, 2, stride=2)\n",
    "        self.dec3 = DoubleConv(f*8, f*4)\n",
    "        self.up2 = nn.ConvTranspose3d(f*4, f*2, 2, stride=2)\n",
    "        self.dec2 = DoubleConv(f*4, f*2)\n",
    "        self.up1 = nn.ConvTranspose3d(f*2, f, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(f*2, f)\n",
    "        self.outc = nn.Conv3d(f, out_ch, 1)\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        b = self.bottleneck(self.pool(e3))\n",
    "        d3 = self.up3(b)\n",
    "        d3 = self.dec3(torch.cat([d3, e3], dim=1))\n",
    "        d2 = self.up2(d3)\n",
    "        d2 = self.dec2(torch.cat([d2, e2], dim=1))\n",
    "        d1 = self.up1(d2)\n",
    "        d1 = self.dec1(torch.cat([d1, e1], dim=1))\n",
    "        return self.outc(d1)\n",
    "\n",
    "# Dice loss\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "    def forward(self, logits, target):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        inter = (probs * target).sum(dim=[1,2,3,4])\n",
    "        denom = probs.sum(dim=[1,2,3,4]) + target.sum(dim=[1,2,3,4])\n",
    "        return 1 - ((2*inter + self.eps) / (denom + self.eps)).mean()\n",
    "\n",
    "def dice_coef(logits, target, eps=1e-6):\n",
    "    pred = (torch.sigmoid(logits) > 0.5).float()\n",
    "    inter = (pred * target).sum(dim=[1,2,3,4])\n",
    "    denom = pred.sum(dim=[1,2,3,4]) + target.sum(dim=[1,2,3,4])\n",
    "    return ((2*inter + eps) / (denom + eps)).mean().item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee724d5",
   "metadata": {},
   "source": [
    "## Entraînement\n",
    "\n",
    "Boucles d'entraînement et d'évaluation. Entraîne sur Timepoint_1+Timepoint_2 et évalue sur Timepoint_3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32480571",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "def train_epoch(model, loader, device, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for imgs, masks, _, _ in tqdm(loader, desc='Train'):\n",
    "        imgs = imgs.to(device)\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def eval_epoch(model, loader, device, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_dice = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks, _, _ in tqdm(loader, desc='Eval'):\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, masks)\n",
    "            total_loss += loss.item()\n",
    "            total_dice += dice_coef(logits, masks)\n",
    "    return total_loss / len(loader), total_dice / len(loader)\n",
    "\n",
    "def inference_and_save(model, loader, device, out_dir):\n",
    "    model.eval()\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks, affines, metas in tqdm(loader, desc='Infer'):\n",
    "            imgs = imgs.to(device)\n",
    "            logits = model(imgs)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            for i in range(probs.shape[0]):\n",
    "                pred = (probs[i,0] > 0.5).astype(np.uint8)\n",
    "                patient, tp = metas[i]\n",
    "                out_path = os.path.join(out_dir, patient, tp, 'pred_mask.nii.gz')\n",
    "                os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "                save_nifti(pred, affines[i], out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1937cbd7",
   "metadata": {},
   "source": [
    "## Exemple d'exécution\n",
    "\n",
    "Modifie `DATASET_DIR` et exécute cette cellule pour lancer l'entraînement (GPU recommandé)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230241c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients retenus: 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/195 [00:21<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 76 but got size 77 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m best_dice \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 33\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     val_loss, val_dice \u001b[38;5;241m=\u001b[39m eval_epoch(model, test_loader, device, criterion)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Val Dice: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_dice\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, device, optimizer, criterion)\u001b[0m\n\u001b[1;32m      7\u001b[0m masks \u001b[38;5;241m=\u001b[39m masks\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 9\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, masks)\n\u001b[1;32m     11\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/projet-AI/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[11], line 35\u001b[0m, in \u001b[0;36mUNet3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m d3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec3(torch\u001b[38;5;241m.\u001b[39mcat([d3, e3], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     34\u001b[0m d2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup2(d3)\n\u001b[0;32m---> 35\u001b[0m d2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec2(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     36\u001b[0m d1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup1(d2)\n\u001b[1;32m     37\u001b[0m d1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec1(torch\u001b[38;5;241m.\u001b[39mcat([d1, e1], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 76 but got size 77 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# Paramètres à éditer par l'utilisateur\n",
    "DATASET_DIR = '/home/perfect/Documents/GitHub/projet-AI/data_filter'   # <-- change\n",
    "OUTPUT_DIR = '/home/perfect/Documents/GitHub/projet-AI/data_segmentation'      # <-- change\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 20\n",
    "LR = 1e-4\n",
    "\n",
    "# Lister patients ayant >=3 timepoints\n",
    "patients = []\n",
    "for p in sorted(os.listdir(DATASET_DIR)):\n",
    "    ppath = os.path.join(DATASET_DIR, p)\n",
    "    if not os.path.isdir(ppath): continue\n",
    "    tps = sorted([d for d in os.listdir(ppath) if os.path.isdir(os.path.join(ppath, d))])\n",
    "    if len(tps) >= 3:\n",
    "        patients.append(p)\n",
    "print(f'Patients retenus: {len(patients)}')\n",
    "\n",
    "# Datasets: train = TP1+TP2, test = TP3\n",
    "train_ds = MRIDataset3D(DATASET_DIR, patients, ['Timepoint_1', 'Timepoint_2'])\n",
    "test_ds  = MRIDataset3D(DATASET_DIR, patients, ['Timepoint_3'])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet3D(in_ch=len(SEQUENCES), out_ch=1).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = DiceLoss()\n",
    "\n",
    "best_dice = 0.0\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_loss = train_epoch(model, train_loader, device, optimizer, criterion)\n",
    "    val_loss, val_dice = eval_epoch(model, test_loader, device, criterion)\n",
    "    print(f'Epoch {epoch}/{EPOCHS} - Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}')\n",
    "    # Save best model\n",
    "    if val_dice > best_dice:\n",
    "        best_dice = val_dice\n",
    "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'best_model.pt'))\n",
    "        print('Best model saved.')\n",
    "\n",
    "# Inference and save\n",
    "inference_and_save(model, test_loader, device, os.path.join(OUTPUT_DIR, 'predictions'))\n",
    "print('Done. Predictions saved to', os.path.join(OUTPUT_DIR, 'predictions'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908d33b",
   "metadata": {},
   "source": [
    "## Visualisation des résultats\n",
    "\n",
    "Affiche des slices (axial) des volumes et des masques (vérité terrain et prédiction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc17b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Exemple pour visualiser un patient/timepoint précis (après inférence)\n",
    "def visualize_patient_timepoint(data_root, patient, timepoint, pred_root=None, slice_idx=None):\n",
    "    tp_path = os.path.join(data_root, patient, timepoint)\n",
    "    channels = []\n",
    "    for seq in SEQUENCES:\n",
    "        f = find_sequence_file(tp_path, seq)\n",
    "        d, _ = load_nifti(f)\n",
    "        channels.append(d)\n",
    "    vol = np.stack(channels, axis=0)\n",
    "    mask_f = find_sequence_file(tp_path, MASK_NAME)\n",
    "    mask, _ = load_nifti(mask_f)\n",
    "    pred_mask = None\n",
    "    if pred_root:\n",
    "        pred_p = os.path.join(pred_root, patient, timepoint, 'pred_mask.nii.gz')\n",
    "        if os.path.exists(pred_p):\n",
    "            pred_mask, _ = load_nifti(pred_p)\n",
    "    show_slices(vol, masks=pred_mask if pred_mask is not None else mask, slice_idx=slice_idx)\n",
    "\n",
    "# Usage example (modifier les chemins et ids)\n",
    "# visualize_patient_timepoint(DATASET_DIR, 'PatientID_0162', 'Timepoint_3', pred_root=os.path.join(OUTPUT_DIR,'predictions'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
